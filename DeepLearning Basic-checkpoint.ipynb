{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11b6d48-acd7-451e-9c60-6b68ee7cbb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------å®‰è£…å’Œåˆå§‹åŒ–æµ‹è¯•-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "066d152d-c56a-4da3-8176-55e8e324256f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-win_amd64.whl (2449.3 MB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-win_amd64.whl (6.1 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp312-cp312-win_amd64.whl (4.1 MB)\n",
      "Requirement already satisfied: filelock in d:\\jupyta\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\jupyta\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in d:\\jupyta\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\jupyta\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\jupyta\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in d:\\jupyta\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\jupyta\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\jupyta\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in d:\\jupyta\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\jupyta\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\jupyta\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121\n"
     ]
    }
   ],
   "source": [
    "# å®‰è£…æ”¯æŒCUDAçš„PyTorchç‰ˆæœ¬\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e41bed99-a9e2-45ea-a0a4-ed30d4e13a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f78144b-5d2a-46bf-87fa-06a51ecfa0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ RTX 4060 GPUåŠ é€Ÿæµ‹è¯•å¼€å§‹ï¼\n",
      "==================================================\n",
      "PyTorchç‰ˆæœ¬: 2.5.1+cu121\n",
      "CUDAæ˜¯å¦å¯ç”¨: True\n",
      "CUDAç‰ˆæœ¬: 12.1\n",
      "GPUåç§°: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "GPUå†…å­˜: 8.0 GB\n",
      "\n",
      "ä½¿ç”¨è®¾å¤‡: cuda\n",
      "\n",
      "ğŸ¯ å¼€å§‹æ€§èƒ½å¯¹æ¯”æµ‹è¯•...\n",
      "çŸ©é˜µå¤§å°: 20000 x 20000\n",
      "â±ï¸  CPUè®¡ç®—æ—¶é—´: 15.4621 ç§’\n",
      "âš¡ GPUè®¡ç®—æ—¶é—´: 2.2528 ç§’\n",
      "ğŸš€ é€Ÿåº¦æå‡: 6.9 å€!\n",
      "âœ… ç»“æœå·®å¼‚: 0.006592\n",
      "\n",
      "ğŸ”§ å¼ é‡æ“ä½œæ¼”ç¤º...\n",
      "å¼ é‡ x:\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], device='cuda:0')\n",
      "å¼ é‡ y:\n",
      "tensor([[5., 6.],\n",
      "        [7., 8.]], device='cuda:0')\n",
      "\n",
      "GPUè¿ç®—ç»“æœ:\n",
      "x + y:\n",
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]], device='cuda:0')\n",
      "x * y:\n",
      "tensor([[ 5., 12.],\n",
      "        [21., 32.]], device='cuda:0')\n",
      "x @ y (çŸ©é˜µä¹˜æ³•):\n",
      "tensor([[19., 22.],\n",
      "        [43., 50.]], device='cuda:0')\n",
      "\n",
      "ğŸ“ è‡ªåŠ¨æ±‚å¯¼æ¼”ç¤º...\n",
      "å‡½æ•°: y = xÂ³ + 2xÂ² + 5x + 1\n",
      "å½“ x = 2 æ—¶:\n",
      "y = 27.0\n",
      "dy/dx = 25.0\n",
      "\n",
      "ğŸ‰ æ­å–œï¼ä½ çš„RTX 4060 GPUåŠ é€Ÿç¯å¢ƒå·²å®Œç¾é…ç½®ï¼\n",
      "âœ¨ ç°åœ¨ä½ å¯ä»¥äº«å—é£å¿«çš„æ·±åº¦å­¦ä¹ è®­ç»ƒé€Ÿåº¦äº†ï¼\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "print(\"ğŸš€ RTX 4060 GPUåŠ é€Ÿæµ‹è¯•å¼€å§‹ï¼\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# æ£€æŸ¥GPUçŠ¶æ€\n",
    "print(f\"PyTorchç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(f\"CUDAæ˜¯å¦å¯ç”¨: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDAç‰ˆæœ¬: {torch.version.cuda}\")\n",
    "print(f\"GPUåç§°: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "# è®¾ç½®è®¾å¤‡\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "\n",
    "# æ€§èƒ½å¯¹æ¯”æµ‹è¯•\n",
    "def performance_test():\n",
    "    print(\"\\nğŸ¯ å¼€å§‹æ€§èƒ½å¯¹æ¯”æµ‹è¯•...\")\n",
    "    \n",
    "    # åˆ›å»ºå¤§å¼ é‡è¿›è¡ŒçŸ©é˜µä¹˜æ³•\n",
    "    size = 20000\n",
    "    print(f\"çŸ©é˜µå¤§å°: {size} x {size}\")\n",
    "    \n",
    "    # CPUè®¡ç®—\n",
    "    a_cpu = torch.randn(size, size)\n",
    "    b_cpu = torch.randn(size, size)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    result_cpu = a_cpu @ b_cpu\n",
    "    cpu_time = time.time() - start_time\n",
    "    print(f\"â±ï¸  CPUè®¡ç®—æ—¶é—´: {cpu_time:.4f} ç§’\")\n",
    "    \n",
    "    # GPUè®¡ç®—\n",
    "    if torch.cuda.is_available():\n",
    "        a_gpu = a_cpu.to(device)\n",
    "        b_gpu = b_cpu.to(device)\n",
    "        \n",
    "        # é¢„çƒ­GPU\n",
    "        _ = a_gpu @ b_gpu\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        result_gpu = a_gpu @ b_gpu\n",
    "        torch.cuda.synchronize()\n",
    "        gpu_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"âš¡ GPUè®¡ç®—æ—¶é—´: {gpu_time:.4f} ç§’\")\n",
    "        print(f\"ğŸš€ é€Ÿåº¦æå‡: {cpu_time/gpu_time:.1f} å€!\")\n",
    "        \n",
    "        # éªŒè¯ç»“æœä¸€è‡´æ€§\n",
    "        difference = torch.max(torch.abs(result_cpu - result_gpu.cpu()))\n",
    "        print(f\"âœ… ç»“æœå·®å¼‚: {difference:.6f}\")\n",
    "\n",
    "# å¼ é‡æ“ä½œç¤ºä¾‹\n",
    "def tensor_operations():\n",
    "    print(\"\\nğŸ”§ å¼ é‡æ“ä½œæ¼”ç¤º...\")\n",
    "    \n",
    "    # åœ¨GPUä¸Šåˆ›å»ºå¼ é‡\n",
    "    x = torch.tensor([[1.0, 2.0], [3.0, 4.0]], device=device)\n",
    "    y = torch.tensor([[5.0, 6.0], [7.0, 8.0]], device=device)\n",
    "    \n",
    "    print(\"å¼ é‡ x:\")\n",
    "    print(x)\n",
    "    print(\"å¼ é‡ y:\")\n",
    "    print(y)\n",
    "    \n",
    "    # GPUä¸Šçš„å„ç§è¿ç®—\n",
    "    z1 = x + y  # åŠ æ³•\n",
    "    z2 = x * y  # ä¹˜æ³•\n",
    "    z3 = x @ y  # çŸ©é˜µä¹˜æ³•\n",
    "    \n",
    "    print(\"\\nGPUè¿ç®—ç»“æœ:\")\n",
    "    print(f\"x + y:\\n{z1}\")\n",
    "    print(f\"x * y:\\n{z2}\")\n",
    "    print(f\"x @ y (çŸ©é˜µä¹˜æ³•):\\n{z3}\")\n",
    "\n",
    "# è‡ªåŠ¨æ±‚å¯¼ç¤ºä¾‹\n",
    "def autograd_demo():\n",
    "    print(\"\\nğŸ“ è‡ªåŠ¨æ±‚å¯¼æ¼”ç¤º...\")\n",
    "    \n",
    "    # åœ¨GPUä¸Šè¿›è¡Œè‡ªåŠ¨æ±‚å¯¼\n",
    "    x = torch.tensor(2.0, requires_grad=True, device=device)\n",
    "    y = x**3 + 2*x**2 + 5*x + 1\n",
    "    \n",
    "    y.backward()\n",
    "    print(f\"å‡½æ•°: y = xÂ³ + 2xÂ² + 5x + 1\")\n",
    "    print(f\"å½“ x = 2 æ—¶:\")\n",
    "    print(f\"y = {y.item()}\")\n",
    "    print(f\"dy/dx = {x.grad.item()}\")  # å¯¼æ•°: 3xÂ² + 4x + 5 = 3*4 + 4*2 + 5 = 25\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    performance_test()\n",
    "    tensor_operations()\n",
    "    autograd_demo()\n",
    "    \n",
    "    print(\"\\nğŸ‰ æ­å–œï¼ä½ çš„RTX 4060 GPUåŠ é€Ÿç¯å¢ƒå·²å®Œç¾é…ç½®ï¼\")\n",
    "    print(\"âœ¨ ç°åœ¨ä½ å¯ä»¥äº«å—é£å¿«çš„æ·±åº¦å­¦ä¹ è®­ç»ƒé€Ÿåº¦äº†ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc7422-fa81-43b3-99b4-db4e29d19ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------æ­£æ–‡-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d610c28b-29c8-48e0-a6d2-2150bd89b518",
   "metadata": {},
   "source": [
    "Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96f714b6-63e1-46bf-b7c4-10323a55debf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.2883, 0.9344],\n",
      "        [0.2310, 0.7040]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.5848, 0.0959, 0.2012],\n",
      "        [0.0842, 0.9143, 0.4248]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "#-------tensor basic grammar-------\n",
    "\n",
    "#ç›´æ¥åˆ›å»º\n",
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "#ä» NumPy æ•°ç»„\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "#ä»å¦ä¸€ä¸ªå¼ é‡ (æ–°å¼ é‡ä¿ç•™å‚æ•°å¼ é‡çš„å±æ€§ï¼ˆå½¢çŠ¶ã€æ•°æ®ç±»å‹ï¼‰ï¼Œé™¤éæ˜¾å¼è¦†ç›–)\n",
    "#åˆ›å»ºä¸€ä¸ªä¸ x_data å½¢çŠ¶ç›¸åŒä½†æ‰€æœ‰å…ƒç´ éƒ½ä¸º1çš„æ–°å¼ é‡\n",
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "#åˆ›å»ºä¸x_dataç›¸åŒå½¢çŠ¶çš„éšæœºå¼ é‡\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")\n",
    "\n",
    "#With random or constant values\n",
    "\n",
    "#shape is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor\n",
    "shape_1d = (5,)        # 1ç»´ï¼Œ5ä¸ªå…ƒç´ çš„ä¸€ç»´æ•°ç»„    å•å…ƒç´ è¦é€—å·ï¼Œå¤šå…ƒç´ ä¸ç”¨ç®¡\n",
    "shape_2d = (2, 3)      # 2ç»´ï¼Œ2è¡Œ3åˆ—çš„çŸ©é˜µ  \n",
    "shape_3d = (2, 3, 4)   # 3ç»´ï¼Œ2ä¸ª3x4çš„çŸ©é˜µ\n",
    "\n",
    "shape = (2,3)\n",
    "rand_tensor = torch.rand(shape) # random variable\n",
    "ones_tensor = torch.ones(shape) # creat a tensor with all value = 1 \n",
    "zeros_tensor = torch.zeros(shape) # creat a tensor with all value = 0 \n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\") # ä½¿ç”¨éšæœºå€¼æˆ–å¸¸é‡å€¼\n",
    "\n",
    "# We move our tensor to the current accelerator if available\n",
    "# if torch.accelerator.is_available():\n",
    "#     tensor = tensor.to(torch.accelerator.current_accelerator())\n",
    "\n",
    "#Standard numpy-like indexing and slicing\n",
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {tensor[0]}\") # è¾“å‡ºç¬¬ä¸€è¡Œ\n",
    "print(f\"First column: {tensor[:, 0]}\") # è¾“å‡ºç¬¬ä¸€åˆ—\n",
    "print(f\"Last column: {tensor[..., -1]}\") # è¾“å‡ºæœ€åä¸€åˆ—\n",
    "tensor[:,1] = 0 # æŠŠç¬¬äºŒåˆ—éƒ½æ¢æˆ0\n",
    "print(tensor)\n",
    "\n",
    "# Joinint tensors using torch.cat\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)\n",
    "\n",
    "#Arithmetic operations\n",
    "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
    "# ``tensor.T`` returns the transpose of a tensor\n",
    "y1 = tensor @ tensor.T # è®¡ç®— tensor ä¸å…¶è½¬ç½®çš„çŸ©é˜µä¹˜æ³•\n",
    "y2 = tensor.matmul(tensor.T) # è®¡ç®— tensor ä¸ tensor.T çš„çŸ©é˜µä¹˜æ³•\n",
    "y3 = torch.rand_like(y1) \n",
    "torch.matmul(tensor, tensor.T, out=y3)   # ä¸‰è€…ç­‰æ•ˆ\n",
    "\n",
    "\n",
    "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
    "z1 = tensor * tensor #å¯¹ tensor çš„æ¯ä¸ªå…ƒç´ è¿›è¡Œå¹³æ–¹ï¼ˆé€å…ƒç´ æ“ä½œï¼Œä¸æ˜¯çŸ©é˜µä¹˜æ³•ï¼‰\n",
    "z2 = tensor.mul(tensor) \n",
    "z3 = torch.rand_like(tensor) \n",
    "torch.mul(tensor, tensor, out=z3) # ä¸‰è€…ç­‰æ•ˆ\n",
    "\n",
    "# convert Single-element tensors to a Python numerical value using :item()\n",
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))\n",
    "\n",
    "# åŸåœ°æ“ä½œ ï¼ˆIn-place Operationsï¼‰\n",
    "tensor.add_(5)  # ç›´æ¥ä¿®æ”¹tensorçš„å†…å®¹  ï¼ˆåœ¨åŸæœ¬çš„æŒ‡ä»¤ä¸ŠåŠ ä¸ªä¸‹åˆ’çº¿å°±æ˜¯åŸåœ°æ“ä½œï¼‰\n",
    "\n",
    "# éåŸåœ°æ“ä½œ - åˆ›å»ºæ–°å¼ é‡\n",
    "new_tensor = tensor.add(5)  # ä¸æ”¹å˜åŸtensor\n",
    "\n",
    "# PyTorchå¼ é‡ â†’ NumPyæ•°ç»„\n",
    "t = torch.ones(5)\n",
    "n = t.numpy()\n",
    "\n",
    "# NumPyæ•°ç»„ â†’ PyTorchå¼ é‡\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b93ba1-0d2c-419d-97de-0ce3ceb59edd",
   "metadata": {},
   "source": [
    "Datasets & DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa81b21-ea44-484a-ace3-20342e5f2128",
   "metadata": {},
   "source": [
    "$#-------Datasets & DataLoaders basic grammar-------$\n",
    "DataLoaderçš„å…³é”®ä½œç”¨ï¼š\n",
    "\n",
    "æ‰¹é‡å¤„ç†ï¼šè‡ªåŠ¨å°†æ ·æœ¬ç»„ç»‡æˆæ‰¹æ¬¡\n",
    "\n",
    "æ•°æ®æ‰“ä¹±ï¼šé˜²æ­¢æ¨¡å‹è¿‡æ‹Ÿåˆ\n",
    "\n",
    "å¹¶è¡ŒåŠ è½½ï¼šä½¿ç”¨å¤šè¿›ç¨‹åŠ é€Ÿæ•°æ®è¯»å–\n",
    "\n",
    "å†…å­˜ä¼˜åŒ–ï¼šæ”¯æŒé”é¡µå†…å­˜ç­‰ä¼˜åŒ–\n",
    "\n",
    "ä½¿ç”¨æ¨¡å¼ï¼š\n",
    "\n",
    "åˆ›å»ºDataset\n",
    "\n",
    "ç”¨DataLoaderåŒ…è£…Dataset\n",
    "\n",
    "åœ¨è®­ç»ƒå¾ªç¯ä¸­è¿­ä»£DataLoader\n",
    "\n",
    "å°†æ‰¹æ¬¡æ•°æ®ä¼ é€’ç»™æ¨¡å‹\n",
    "\n",
    "é‡è¦å‚æ•°ï¼š\n",
    "\n",
    "batch_sizeï¼šæ ¹æ®GPUå†…å­˜è°ƒæ•´\n",
    "\n",
    "shuffleï¼šè®­ç»ƒé›†ä¸ºTrueï¼Œæµ‹è¯•é›†ä¸ºFalse\n",
    "\n",
    "num_workersï¼šæ ¹æ®CPUæ ¸å¿ƒæ•°è°ƒæ•´\n",
    "\n",
    "pin_memoryï¼šä½¿ç”¨GPUæ—¶è®¾ä¸ºTrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d420b946-2709-4cd7-855b-cadbb0b3928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------åˆ›å»ºæ•°æ®é›†åŸºç¡€è¯­æ³•------\n",
    "#å¯¼å…¥åº“\n",
    "import os # ç”¨äºå¤„ç†æ–‡ä»¶è·¯å¾„\n",
    "import pandas as pd # ç”¨äºè¯»å–CSVæ ‡æ³¨æ–‡ä»¶\n",
    "from torchvision.io import decode_image # ä»æ–‡ä»¶è·¯å¾„è¯»å–å¹¶è§£ç å›¾åƒä¸ºTensor\n",
    "\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    \n",
    "    # å‚æ•°è¯´æ˜ï¼š\n",
    "        # annotations_file: CSVæ–‡ä»¶è·¯å¾„ï¼ŒåŒ…å«å›¾åƒæ–‡ä»¶åå’Œå¯¹åº”æ ‡ç­¾\n",
    "        # img_dir: å›¾åƒæ–‡ä»¶å­˜å‚¨çš„ç›®å½•è·¯å¾„\n",
    "        # transform: å›¾åƒé¢„å¤„ç†å˜æ¢ï¼ˆå¦‚è°ƒæ•´å¤§å°ã€å½’ä¸€åŒ–ç­‰ï¼‰\n",
    "        # target_transform: æ ‡ç­¾é¢„å¤„ç†å˜æ¢\n",
    "    \n",
    "    # __init__ ä½œç”¨ï¼šåˆå§‹åŒ–æ•°æ®é›†å¯¹è±¡ï¼Œè¯»å–æ ‡æ³¨æ–‡ä»¶ï¼Œè®¾ç½®å›¾åƒç›®å½•å’Œå˜æ¢å‡½æ•°\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform  #å¦‚ transform=ToTensor(), å°†å›¾åƒè½¬æ¢ä¸ºTensor\n",
    "\n",
    "    #__len__ ä½œç”¨ï¼šè¿”å›æ•°æ®é›†ä¸­æ ·æœ¬çš„æ•°é‡\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels) #å®ç°ï¼šé€šå¸¸è¿”å›æ ‡æ³¨æ–‡ä»¶ä¸­çš„è¡Œæ•°\n",
    "\n",
    "    #__getitem__ ä½œç”¨ï¼šæ ¹æ®ç´¢å¼•idxè·å–ä¸€ä¸ªæ ·æœ¬ï¼ˆå›¾åƒå’Œæ ‡ç­¾ï¼‰\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = decode_image(img_path) #è¯»å–å›¾åƒæ–‡ä»¶å¹¶è§£ç ä¸ºPyTorch Tensorï¼Œ è¿”å›çš„Tensorå½¢çŠ¶ä¸º [channels, height, width]\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:                        #åº”ç”¨å›¾åƒå˜æ¢ï¼ˆå¦‚å½’ä¸€åŒ–ã€æ•°æ®å¢å¼ºç­‰ï¼‰\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:                 #åº”ç”¨æ ‡ç­¾å˜æ¢ï¼ˆå¦‚one-hotç¼–ç ç­‰ï¼‰\n",
    "            label = self.target_transform(label)\n",
    "        return image, label   #è¿”å›å›¾åƒTensorå’Œå¯¹åº”çš„æ ‡ç­¾\n",
    "\n",
    "\n",
    "# ç”¨ DataLoaders æ¥å‡†å¤‡è®­ç»ƒæ•°æ®\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)  \n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_dataloader = DataLoader(\n",
    "#     dataset=training_data,      # æ•°æ®é›†å¯¹è±¡\n",
    "#     batch_size=64,              # æ‰¹é‡å¤§å°\n",
    "#     shuffle=True,               # æ˜¯å¦æ‰“ä¹±æ•°æ®\n",
    "#     num_workers=4,              # ç”¨äºæ•°æ®åŠ è½½çš„å­è¿›ç¨‹æ•°\n",
    "#     pin_memory=True,            # é”é¡µå†…å­˜ï¼ŒåŠ é€ŸGPUä¼ è¾“\n",
    "#     drop_last=False,            # æ˜¯å¦ä¸¢å¼ƒæœ€åä¸€ä¸ªä¸å®Œæ•´çš„æ‰¹æ¬¡\n",
    "#     persistent_workers=True     # ä¿æŒworkerè¿›ç¨‹æ´»è·ƒ\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "#è¿­ä»£DataLoader ï¼ˆIterate through the DataLoaderï¼‰\n",
    "\n",
    "#åŸºæœ¬è¿­ä»£æ–¹å¼\n",
    "    # æ–¹æ³•1: ç›´æ¥è¿­ä»£\n",
    "    for batch_idx, (images, labels) in enumerate(train_dataloader):\n",
    "        print(f\"Batch {batch_idx}: images shape {images.shape}, labels shape {labels.shape}\")\n",
    "        \n",
    "        # è®­ç»ƒä»£ç ...\n",
    "        if batch_idx == 2:  # åªæ¼”ç¤ºå‰3ä¸ªæ‰¹æ¬¡\n",
    "            break\n",
    "\n",
    "# ä½¿ç”¨ next(iter()) è·å–å•ä¸ªæ‰¹æ¬¡\n",
    "    # è·å–ç¬¬ä¸€ä¸ªæ‰¹æ¬¡è¿›è¡Œæ¼”ç¤º\n",
    "    train_features, train_labels = next(iter(train_dataloader))\n",
    "    \n",
    "    print(f\"Feature batch shape: {train_features.size()}\")\n",
    "    print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DataLoader é«˜çº§ç”¨æ³•\n",
    "    # ä¸åŒæ‰¹é‡å¤§å°è®¾ç½®\n",
    "        # æ ¹æ®ä»»åŠ¡ç±»å‹è®¾ç½®ä¸åŒçš„æ‰¹é‡å¤§å°\n",
    "        small_batch_loader = DataLoader(training_data, batch_size=16, shuffle=True)   # å°æ‰¹é‡ï¼Œé€‚åˆå°æ¨¡å‹\n",
    "        large_batch_loader = DataLoader(training_data, batch_size=256, shuffle=True)  # å¤§æ‰¹é‡ï¼Œé€‚åˆå¤§æ¨¡å‹\n",
    "        \n",
    "        print(f\"å°æ‰¹é‡æ•°æ®å½¢çŠ¶: {next(iter(small_batch_loader))[0].shape}\")  # [16, 1, 28, 28]\n",
    "        print(f\"å¤§æ‰¹é‡æ•°æ®å½¢çŠ¶: {next(iter(large_batch_loader))[0].shape}\")  # [256, 1, 28, 28]\n",
    "\n",
    "    # æ€§èƒ½ä¼˜åŒ–å‚æ•°\n",
    "        # ä¼˜åŒ–æ€§èƒ½çš„DataLoaderé…ç½®\n",
    "        optimized_loader = DataLoader(\n",
    "            training_data,\n",
    "            batch_size=64,\n",
    "            shuffle=True,\n",
    "            num_workers=4,           # å¹¶è¡ŒåŠ è½½è¿›ç¨‹æ•°\n",
    "            pin_memory=True,         # é”é¡µå†…å­˜ï¼ŒåŠ é€ŸGPUæ•°æ®ä¼ è¾“\n",
    "            drop_last=True,          # ä¸¢å¼ƒæœ€åä¸€ä¸ªä¸å®Œæ•´æ‰¹æ¬¡\n",
    "            persistent_workers=True  # ä¿æŒworkerè¿›ç¨‹ï¼Œé¿å…é‡å¤åˆ›å»º\n",
    "        )\n",
    "        \n",
    "        # æ³¨æ„ï¼šåœ¨Windowsä¸Šï¼Œnum_workers=0å¯ä»¥é¿å…ä¸€äº›é—®é¢˜\n",
    "\n",
    "# æ€§èƒ½ä¼˜åŒ–\n",
    "    # ä½¿ç”¨DataLoaderçš„å¤šè¿›ç¨‹åŠ è½½\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=4,        # å¹¶è¡ŒåŠ è½½è¿›ç¨‹æ•°\n",
    "        pin_memory=True,      # åŠ é€ŸGPUä¼ è¾“\n",
    "        persistent_workers=True  # ä¿æŒworkerè¿›ç¨‹\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933577b-0de1-4a17-b15f-ddeb948e7c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----é‡è¦æ³¨æ„äº‹é¡¹----\n",
    "# decode_imageåº”è¯¥æ˜¯read_image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Transforms\n",
    "    from torchvision import transforms\n",
    "    \n",
    "    # å¸¸ç”¨çš„å›¾åƒå˜æ¢ç»„åˆ\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),      # è°ƒæ•´å¤§å°\n",
    "        transforms.RandomHorizontalFlip(),  # æ•°æ®å¢å¼ºï¼šéšæœºæ°´å¹³ç¿»è½¬\n",
    "        transforms.ToTensor(),              # è½¬æ¢ä¸ºTensor (0-1èŒƒå›´)\n",
    "        transforms.Normalize(               # å½’ä¸€åŒ–\n",
    "            mean=[0.485, 0.456, 0.406],    # ImageNetå‡å€¼\n",
    "            std=[0.229, 0.224, 0.225]      # ImageNetæ ‡å‡†å·®\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    # æ ‡ç­¾å˜æ¢ç¤ºä¾‹\n",
    "    def target_transform(label):\n",
    "        # ä¾‹å¦‚ï¼šå°†æ ‡ç­¾è½¬æ¢ä¸ºone-hotç¼–ç \n",
    "        return torch.nn.functional.one_hot(torch.tensor(label), num_classes=10)\n",
    "\n",
    "\n",
    "# é”™è¯¯å¤„ç†\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "            image = read_image(img_path)\n",
    "            label = self.img_labels.iloc[idx, 1]\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            if self.target_transform:\n",
    "                label = self.target_transform(label)\n",
    "                \n",
    "            return image, label\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"åŠ è½½æ ·æœ¬ {idx} æ—¶å‡ºé”™: {e}\")\n",
    "            # è¿”å›ä¸€ä¸ªé»˜è®¤æ ·æœ¬æˆ–è·³è¿‡\n",
    "            return torch.zeros(3, 224, 224), -1\n",
    "\n",
    "\n",
    "# æ”¯æŒä¸åŒçš„æ•°æ®æ ¼å¼\n",
    "class FlexibleDataset(Dataset):\n",
    "    def __init__(self, data_frame, img_dir, transform=None):\n",
    "        self.data_frame = data_frame\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data_frame.iloc[idx]\n",
    "        \n",
    "        # æ”¯æŒä¸åŒçš„åˆ—å\n",
    "        img_path = os.path.join(self.img_dir, \n",
    "                               getattr(row, 'filename', None) or \n",
    "                               getattr(row, 'image_path', None) or \n",
    "                               row[0])\n",
    "        \n",
    "        # æ”¯æŒä¸åŒçš„æ ‡ç­¾åˆ—å\n",
    "        label = getattr(row, 'label', None) or \\\n",
    "                getattr(row, 'class', None) or \\\n",
    "                getattr(row, 'category', None) or \\\n",
    "                row[1]\n",
    "        \n",
    "        image = read_image(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "# shuffleå‚æ•°çš„é‡è¦æ€§\n",
    "    # è®­ç»ƒé›†ï¼šshuffle=Trueï¼ˆé˜²æ­¢æ¨¡å‹è®°ä½æ•°æ®é¡ºåºï¼‰\n",
    "        train_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "    \n",
    "    # æµ‹è¯•é›†ï¼šshuffle=Falseï¼ˆä¿æŒä¸€è‡´æ€§ï¼Œä¾¿äºåˆ†æï¼‰\n",
    "        test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# drop_lastå‚æ•°\n",
    "    # å½“æ•°æ®é›†å¤§å°ä¸èƒ½è¢«batch_sizeæ•´é™¤æ—¶\n",
    "        dataset_size = 100\n",
    "        batch_size = 30\n",
    "            \n",
    "        loader_drop_false = DataLoader(dataset, batch_size=30, drop_last=False)\n",
    "        loader_drop_true = DataLoader(dataset, batch_size=30, drop_last=True)\n",
    "        \n",
    "        print(f\"drop_last=False çš„æ‰¹æ¬¡æ•°: {len(loader_drop_false)}\")  # 4ä¸ªæ‰¹æ¬¡ (30,30,30,10)\n",
    "        print(f\"drop_last=True çš„æ‰¹æ¬¡æ•°: {len(loader_drop_true)}\")   # 3ä¸ªæ‰¹æ¬¡ (30,30,30)\n",
    "\n",
    "# å†…å­˜ç®¡ç†\n",
    "    # ç›‘æ§æ•°æ®åŠ è½½çš„å†…å­˜ä½¿ç”¨\n",
    "        for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "            print(f\"æ‰¹æ¬¡ {batch_idx} å†…å­˜ä½¿ç”¨: {data.element_size() * data.nelement() / 1024 / 1024:.2f} MB\")\n",
    "            \n",
    "            if batch_idx == 0:\n",
    "                # æ£€æŸ¥è®¾å¤‡\n",
    "                print(f\"æ•°æ®è®¾å¤‡: {data.device}\")\n",
    "                print(f\"æ ‡ç­¾è®¾å¤‡: {target.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2547cb-42a1-48a7-8c74-d9a6b1ed502c",
   "metadata": {},
   "source": [
    "$DataLoader å®Œæ•´å…¬å¼åŒ–ä¾‹ç¨‹$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad51c6f5-2aca-4066-9be9-03455cf58d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­ä¿è¯å¯é‡å¤æ€§\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class CompleteDataLoaderExample:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"ä½¿ç”¨è®¾å¤‡: {self.device}\")\n",
    "        \n",
    "        # æ•°æ®å˜æ¢\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "        \n",
    "        # åŠ è½½æ•°æ®\n",
    "        self.train_dataset, self.test_dataset = self.load_data()\n",
    "        \n",
    "        # åˆ›å»ºDataLoader\n",
    "        self.train_loader, self.test_loader = self.create_dataloaders()\n",
    "        \n",
    "        # åˆ›å»ºæ¨¡å‹\n",
    "        self.model = self.create_model().to(self.device)\n",
    "        \n",
    "        # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        \n",
    "        # è®­ç»ƒè®°å½•\n",
    "        self.train_losses = []\n",
    "        self.test_accuracies = []\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"åŠ è½½è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†\"\"\"\n",
    "        print(\"æ­£åœ¨ä¸‹è½½å’ŒåŠ è½½æ•°æ®...\")\n",
    "        \n",
    "        train_dataset = datasets.FashionMNIST(\n",
    "            root='./data',\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=self.transform\n",
    "        )\n",
    "        \n",
    "        test_dataset = datasets.FashionMNIST(\n",
    "            root='./data',\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=self.transform\n",
    "        )\n",
    "        \n",
    "        print(f\"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}\")\n",
    "        print(f\"æµ‹è¯•é›†å¤§å°: {len(test_dataset)}\")\n",
    "        \n",
    "        return train_dataset, test_dataset\n",
    "\n",
    "    def create_dataloaders(self):\n",
    "        \"\"\"åˆ›å»ºè®­ç»ƒå’Œæµ‹è¯•DataLoader\"\"\"\n",
    "        train_loader = DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=64,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        test_loader = DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=1000,\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        print(f\"è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}\")\n",
    "        print(f\"æµ‹è¯•æ‰¹æ¬¡æ•°: {len(test_loader)}\")\n",
    "        \n",
    "        return train_loader, test_loader\n",
    "\n",
    "    def create_model(self):\n",
    "        \"\"\"åˆ›å»ºç®€å•çš„ç¥ç»ç½‘ç»œæ¨¡å‹\"\"\"\n",
    "        class SimpleNN(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(SimpleNN, self).__init__()\n",
    "                self.flatten = nn.Flatten()\n",
    "                self.linear_relu_stack = nn.Sequential(\n",
    "                    nn.Linear(28*28, 512),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(512, 512),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(512, 10)\n",
    "                )\n",
    "            \n",
    "            def forward(self, x):\n",
    "                x = self.flatten(x)\n",
    "                logits = self.linear_relu_stack(x)\n",
    "                return logits\n",
    "        \n",
    "        return SimpleNN()\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"è®­ç»ƒä¸€ä¸ªepoch\"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "            # å°†æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            \n",
    "            # å‰å‘ä¼ æ’­\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = self.criterion(output, target)\n",
    "            \n",
    "            # åå‘ä¼ æ’­\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # æ¯100ä¸ªæ‰¹æ¬¡æ‰“å°ä¸€æ¬¡è¿›åº¦\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(self.train_loader.dataset)} '\n",
    "                      f'({100. * batch_idx / len(self.train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "        \n",
    "        avg_loss = running_loss / len(self.train_loader)\n",
    "        self.train_losses.append(avg_loss)\n",
    "        return avg_loss\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"æµ‹è¯•æ¨¡å‹æ€§èƒ½\"\"\"\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in self.test_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.model(data)\n",
    "                test_loss += self.criterion(output, target).item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        test_loss /= len(self.test_loader)\n",
    "        accuracy = 100. * correct / len(self.test_loader.dataset)\n",
    "        self.test_accuracies.append(accuracy)\n",
    "        \n",
    "        print(f'\\næµ‹è¯•é›†: å¹³å‡æŸå¤±: {test_loss:.4f}, å‡†ç¡®ç‡: {correct}/{len(self.test_loader.dataset)} '\n",
    "              f'({accuracy:.2f}%)\\n')\n",
    "        \n",
    "        return accuracy\n",
    "\n",
    "    def visualize_batch(self, num_images=12):\n",
    "        \"\"\"å¯è§†åŒ–ä¸€ä¸ªæ‰¹æ¬¡çš„æ ·æœ¬\"\"\"\n",
    "        # è·å–ä¸€ä¸ªæ‰¹æ¬¡\n",
    "        data_iter = iter(self.train_loader)\n",
    "        images, labels = next(data_iter)\n",
    "        \n",
    "        # æ ‡ç­¾æ˜ å°„\n",
    "        class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                      'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "        \n",
    "        # åˆ›å»ºå›¾åƒç½‘æ ¼\n",
    "        fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "        for i in range(num_images):\n",
    "            ax = axes[i // 4, i % 4]\n",
    "            image = images[i].squeeze()\n",
    "            label = labels[i].item()\n",
    "            \n",
    "            ax.imshow(image, cmap='gray')\n",
    "            ax.set_title(f'{class_names[label]} ({label})')\n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_training(self):\n",
    "        \"\"\"å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        # è®­ç»ƒæŸå¤±\n",
    "        ax1.plot(self.train_losses)\n",
    "        ax1.set_title('è®­ç»ƒæŸå¤±')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # æµ‹è¯•å‡†ç¡®ç‡\n",
    "        ax2.plot(self.test_accuracies)\n",
    "        ax2.set_title('æµ‹è¯•å‡†ç¡®ç‡')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Accuracy (%)')\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def run_training(self, epochs=5):\n",
    "        \"\"\"è¿è¡Œå®Œæ•´è®­ç»ƒè¿‡ç¨‹\"\"\"\n",
    "        print(\"å¼€å§‹è®­ç»ƒ...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(1, epochs + 1):\n",
    "            epoch_start = time.time()\n",
    "            \n",
    "            # è®­ç»ƒä¸€ä¸ªepoch\n",
    "            train_loss = self.train_epoch(epoch)\n",
    "            \n",
    "            # æµ‹è¯•\n",
    "            test_accuracy = self.test()\n",
    "            \n",
    "            epoch_time = time.time() - epoch_start\n",
    "            print(f'Epoch {epoch} å®Œæˆ, è€—æ—¶: {epoch_time:.2f}ç§’')\n",
    "            print('-' * 50)\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f'è®­ç»ƒå®Œæˆ! æ€»è€—æ—¶: {total_time:.2f}ç§’')\n",
    "        \n",
    "        # å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹\n",
    "        self.visualize_training()\n",
    "\n",
    "    def demonstrate_dataloader_features(self):\n",
    "        \"\"\"æ¼”ç¤ºDataLoaderçš„å„ç§ç‰¹æ€§\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"DataLoader ç‰¹æ€§æ¼”ç¤º\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # 1. æ˜¾ç¤ºæ‰¹æ¬¡ä¿¡æ¯\n",
    "        print(\"1. æ‰¹æ¬¡ä¿¡æ¯:\")\n",
    "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "            if batch_idx == 0:\n",
    "                print(f\"  æ•°æ®å½¢çŠ¶: {data.shape}\")  # [batch_size, channels, height, width]\n",
    "                print(f\"  æ ‡ç­¾å½¢çŠ¶: {target.shape}\")  # [batch_size]\n",
    "                print(f\"  æ•°æ®ç±»å‹: {data.dtype}\")\n",
    "                print(f\"  æ•°æ®èŒƒå›´: [{data.min():.3f}, {data.max():.3f}]\")\n",
    "            break\n",
    "        \n",
    "        # 2. æ˜¾ç¤ºshuffleæ•ˆæœ\n",
    "        print(\"\\n2. Shuffleæ•ˆæœæ¼”ç¤º:\")\n",
    "        first_batch_labels = []\n",
    "        for i in range(3):\n",
    "            data_iter = iter(self.train_loader)\n",
    "            _, labels = next(data_iter)\n",
    "            first_batch_labels.append(labels[:5].tolist())  # å‰5ä¸ªæ ‡ç­¾\n",
    "        \n",
    "        print(\"   å‰3æ¬¡è¿­ä»£çš„ç¬¬ä¸€ä¸ªæ‰¹æ¬¡çš„å‰5ä¸ªæ ‡ç­¾:\")\n",
    "        for i, labels in enumerate(first_batch_labels):\n",
    "            print(f\"   è¿­ä»£ {i+1}: {labels}\")\n",
    "        \n",
    "        # 3. æ˜¾ç¤ºæ•°æ®é›†ä¿¡æ¯\n",
    "        print(\"\\n3. æ•°æ®é›†ç»Ÿè®¡:\")\n",
    "        print(f\"   è®­ç»ƒé›†æ€»æ ·æœ¬æ•°: {len(self.train_loader.dataset)}\")\n",
    "        print(f\"   æµ‹è¯•é›†æ€»æ ·æœ¬æ•°: {len(self.test_loader.dataset)}\")\n",
    "        print(f\"   è®­ç»ƒæ‰¹æ¬¡æ•°: {len(self.train_loader)}\")\n",
    "        print(f\"   æµ‹è¯•æ‰¹æ¬¡æ•°: {len(self.test_loader)}\")\n",
    "        print(f\"   æ‰¹æ¬¡å¤§å°: {self.train_loader.batch_size}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"ä¸»å‡½æ•°\"\"\"\n",
    "    # åˆ›å»ºç¤ºä¾‹\n",
    "    example = CompleteDataLoaderExample()\n",
    "    \n",
    "    # å¯è§†åŒ–ä¸€äº›æ ·æœ¬\n",
    "    print(\"æ­£åœ¨å¯è§†åŒ–è®­ç»ƒæ ·æœ¬...\")\n",
    "    example.visualize_batch()\n",
    "    \n",
    "    # æ¼”ç¤ºDataLoaderç‰¹æ€§\n",
    "    example.demonstrate_dataloader_features()\n",
    "    \n",
    "    # è¿è¡Œè®­ç»ƒ\n",
    "    example.run_training(epochs=5)\n",
    "    \n",
    "    # ä¿å­˜æ¨¡å‹\n",
    "    torch.save(example.model.state_dict(), 'fashion_mnist_model.pth')\n",
    "    print(\"æ¨¡å‹å·²ä¿å­˜ä¸º 'fashion_mnist_model.pth'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b005b955-96ad-4349-9d7d-2b129bb3a46a",
   "metadata": {},
   "source": [
    "$å…³é”®ç»„ä»¶è¯´æ˜ æ•°æ®åŠ è½½ â†’ æ¨¡å‹å®šä¹‰ â†’ è®­ç»ƒ â†’ æµ‹è¯• â†’ å¯è§†åŒ–$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631e3786-1013-4682-b7c4-1e85972a019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 æ•°æ®åŠ è½½å’Œé¢„å¤„ç†\n",
    "# æ ‡å‡†æ•°æ®å˜æ¢\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),           # è½¬æ¢ä¸ºTensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # å½’ä¸€åŒ–åˆ°[-1,1]\n",
    "])\n",
    "\n",
    "# æ•°æ®é›†åŠ è½½\n",
    "train_dataset = datasets.FashionMNIST(...)\n",
    "test_dataset = datasets.FashionMNIST(...)\n",
    "\n",
    "#2 DataLoaderé…ç½®\n",
    "# è®­ç»ƒDataLoader - æ‰“ä¹±æ•°æ®ï¼Œé€‚åˆè®­ç»ƒ\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,        # é‡è¦ï¼šè®­ç»ƒæ—¶éœ€è¦æ‰“ä¹±\n",
    "    num_workers=2,       # å¹¶è¡ŒåŠ è½½è¿›ç¨‹\n",
    "    pin_memory=True      # åŠ é€ŸGPUä¼ è¾“\n",
    ")\n",
    "\n",
    "# æµ‹è¯•DataLoader - ä¸æ‰“ä¹±æ•°æ®ï¼Œé€‚åˆè¯„ä¼°\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1000,     # æµ‹è¯•æ—¶å¯ä»¥ç”¨æ›´å¤§çš„æ‰¹æ¬¡\n",
    "    shuffle=False,       # é‡è¦ï¼šæµ‹è¯•æ—¶ä¸éœ€è¦æ‰“ä¹±\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "#3 æ ‡å‡†è®­ç»ƒå¾ªç¯æ¨¡æ¿\n",
    "def train_epoch(self, epoch):\n",
    "    self.model.train()  # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼\n",
    "    for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "        # 1. æ•°æ®ç§»åŠ¨åˆ°è®¾å¤‡\n",
    "        data, target = data.to(self.device), target.to(self.device)\n",
    "        \n",
    "        # 2. æ¢¯åº¦æ¸…é›¶\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # 3. å‰å‘ä¼ æ’­\n",
    "        output = self.model(data)\n",
    "        loss = self.criterion(output, target)\n",
    "        \n",
    "        # 4. åå‘ä¼ æ’­\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. å‚æ•°æ›´æ–°\n",
    "        self.optimizer.step()\n",
    "\n",
    "#4 æ ‡å‡†æµ‹è¯•å¾ªç¯æ¨¡æ¿\n",
    "def test(self):\n",
    "    self.model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "    with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦è®¡ç®—\n",
    "        for data, target in self.test_loader:\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            output = self.model(data)\n",
    "            # è®¡ç®—å‡†ç¡®ç‡ç­‰æŒ‡æ ‡..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36374860-02a2-4077-8cce-f88024085546",
   "metadata": {},
   "source": [
    "$Transforms$\n",
    "\n",
    "$Transformsæ˜¯æ•°æ®é¢„å¤„ç†çš„å·¥å…·ï¼Œç”¨äºå°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºé€‚åˆæ¨¡å‹è®­ç»ƒçš„æ ¼å¼$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56244a7-47db-4eb1-a0f2-aebcde9efea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "# åº”ç”¨ToTensorè½¬æ¢\n",
    "to_tensor = ToTensor()\n",
    "tensor_image = to_tensor(pil_image)\n",
    "\n",
    "# Lambda Transforms\n",
    "target_transform = Lambda(lambda y: torch.zeros(\n",
    "    10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))\n",
    "\n",
    "    # Within Lambda Transforms\n",
    "        # æ­¥éª¤1: åˆ›å»ºå…¨é›¶å¼ é‡\n",
    "            zero_tensor = torch.zeros(10, dtype=torch.float)\n",
    "            # tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "        \n",
    "        # æ­¥éª¤2: ä½¿ç”¨scatter_åœ¨æŒ‡å®šä½ç½®è®¾ç½®å€¼\n",
    "            result = zero_tensor.scatter_(dim=0, index=torch.tensor(3), value=1)\n",
    "            # tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
    "\n",
    "# å¸¸ç”¨Transforms\n",
    "from torchvision import transforms\n",
    "\n",
    "# å¸¸ç”¨çš„å›¾åƒå˜æ¢ç»„åˆ\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),                    # è°ƒæ•´å¤§å°\n",
    "    transforms.CenterCrop(224),                # ä¸­å¿ƒè£å‰ª\n",
    "    transforms.RandomHorizontalFlip(0.5),     # éšæœºæ°´å¹³ç¿»è½¬\n",
    "    transforms.RandomRotation(10),             # éšæœºæ—‹è½¬\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2),    # é¢œè‰²æŠ–åŠ¨\n",
    "    transforms.ToTensor(),                     # è½¬æ¢ä¸ºTensor\n",
    "    transforms.Normalize(                      # å½’ä¸€åŒ–\n",
    "        mean=[0.485, 0.456, 0.406],           # ImageNetå‡å€¼\n",
    "        std=[0.229, 0.224, 0.225]             # ImageNetæ ‡å‡†å·®\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b843f9c5-7e65-4097-90d2-46e4db4afc84",
   "metadata": {},
   "source": [
    "$ToTensor()$å®Œæˆä¸¤ä¸ªä¸»è¦è½¬æ¢ï¼š\n",
    "\n",
    "è½¬æ¢å‰ï¼šPIL Image æˆ– numpy.ndarray\n",
    "\n",
    "è½¬æ¢åï¼štorch.FloatTensor\n",
    "\n",
    "å…·ä½“å˜åŒ–ï¼š\n",
    "1. æ•°æ®ç±»å‹ï¼šPIL/NumPy â†’ torch.Tensor\n",
    "2. æ•°å€¼èŒƒå›´ï¼š[0, 255] â†’ [0.0, 1.0]\n",
    "3. ç»´åº¦é¡ºåºï¼š(H, W, C) â†’ (C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a041db77-28a9-4efc-bced-2da9511ea30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®é™…åº”ç”¨ï¼ˆè®­ç»ƒå’Œæµ‹è¯•çš„ä¸åŒå˜æ¢ï¼‰\n",
    "    # è®­ç»ƒå˜æ¢ï¼šåŒ…å«æ•°æ®å¢å¼º\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # æµ‹è¯•å˜æ¢ï¼šåªæœ‰åŸºç¡€å˜æ¢\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # åˆ†åˆ«åº”ç”¨äºè®­ç»ƒé›†å’Œæµ‹è¯•é›†\n",
    "    train_dataset = datasets.FashionMNIST(\n",
    "        root=\"data\", train=True, download=True, transform=train_transform\n",
    "    )\n",
    "    \n",
    "    test_dataset = datasets.FashionMNIST(\n",
    "        root=\"data\", train=False, download=True, transform=test_transform\n",
    "    )\n",
    "\n",
    "#----æ³¨æ„äº‹é¡¹----\n",
    "    # å˜æ¢çš„é¡ºåºå¾ˆé‡è¦\n",
    "        # é”™è¯¯é¡ºåº\n",
    "        wrong_order = transforms.Compose([\n",
    "            transforms.Normalize((0.5,), (0.5,)),  # é”™è¯¯ï¼šåœ¨ToTensorä¹‹å‰\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        # æ­£ç¡®é¡ºåº\n",
    "        correct_order = transforms.Compose([\n",
    "            transforms.ToTensor(),                  # å…ˆè½¬æ¢ä¸ºTensor\n",
    "            transforms.Normalize((0.5,), (0.5,))   # ç„¶åå½’ä¸€åŒ–\n",
    "        ])\n",
    "    \n",
    "    # å†…å­˜å’Œæ€§èƒ½è€ƒè™‘\n",
    "        # é¿å…åœ¨å˜æ¢ä¸­è¿›è¡Œæ˜‚è´µçš„æ“ä½œ\n",
    "        # ä¸å¥½ï¼šåœ¨æ¯æ¬¡è·å–æ ·æœ¬æ—¶éƒ½è¿›è¡Œå¤æ‚è®¡ç®—\n",
    "        expensive_transform = Lambda(lambda x: complicated_processing(x))\n",
    "        \n",
    "        # å¥½ï¼šé¢„å¤„ç†æˆ–ä½¿ç”¨ç¼“å­˜çš„å˜æ¢\n",
    "        efficient_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "    \n",
    "    # æ•°æ®ç±»å‹ä¸€è‡´æ€§\n",
    "        # ç¡®ä¿å˜æ¢åçš„æ•°æ®ç±»å‹ä¸æ¨¡å‹æœŸæœ›ä¸€è‡´\n",
    "        def check_data_types(dataset):\n",
    "            image, label = dataset[0]\n",
    "            \n",
    "            print(f\"å›¾åƒç±»å‹: {image.dtype}\")    # åº”è¯¥æ˜¯torch.float32\n",
    "            print(f\"æ ‡ç­¾ç±»å‹: {label.dtype}\")    # åº”è¯¥æ˜¯torch.float32ï¼ˆå¯¹äºone-hotï¼‰\n",
    "            \n",
    "            # æ¨¡å‹é€šå¸¸æœŸæœ›float32è¾“å…¥\n",
    "            assert image.dtype == torch.float32, f\"å›¾åƒæ•°æ®ç±»å‹é”™è¯¯: {image.dtype}\"\n",
    "            assert label.dtype == torch.float32, f\"æ ‡ç­¾æ•°æ®ç±»å‹é”™è¯¯: {label.dtype}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693095d1-2f8d-4701-8fd2-c8c4c54f5969",
   "metadata": {},
   "source": [
    "$Build-the-Neural-Network$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c6246a-d81f-4fce-9828-43a2ecdb8b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary library\n",
    "import os\n",
    "import torch\n",
    "from torch import nn  # ç¥ç»ç½‘ç»œæ ¸å¿ƒæ¨¡å— torch.nnï¼šåŒ…å«æ‰€æœ‰ç¥ç»ç½‘ç»œå±‚å’ŒæŸå¤±å‡½æ•°\n",
    "from torch.utils.data import DataLoader  # æ•°æ®åŠ è½½ DataLoaderï¼šç”¨äºæ‰¹é‡åŠ è½½æ•°æ®\n",
    "from torchvision import datasets, transforms  # è®¡ç®—æœºè§†è§‰ç›¸å…³ torchvisionï¼šæä¾›é¢„è®­ç»ƒæ¨¡å‹å’Œæ•°æ®é›†\n",
    "\n",
    "\n",
    "# Get Device for Training\n",
    "# æ–¹æ³•1ï¼šä½¿ç”¨æœ€æ–°çš„åŠ é€Ÿå™¨APIï¼ˆæ¨èï¼‰\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "    # æ–¹æ³•2ï¼šä¼ ç»Ÿæ–¹æ³•ï¼ˆå…¼å®¹æ€§æ›´å¥½ï¼‰\n",
    "        # if torch.cuda.is_available():\n",
    "        #     device = \"cuda\"\n",
    "        # elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        #     device = \"mps\"  # Apple Silicon\n",
    "        # else:\n",
    "        #     device = \"cpu\"\n",
    "\n",
    "\n",
    "# Define the Class ç¥ç»ç½‘ç»œç±»çš„éª¨æ¶\n",
    "\"\"\"\" \n",
    "å…³é”®è§„åˆ™ï¼š\n",
    "\n",
    "å¿…é¡»ç»§æ‰¿ nn.Module\n",
    "\n",
    "å¿…é¡»è°ƒç”¨ super().__init__()\n",
    "\n",
    "å¿…é¡»å®ç° forward æ–¹æ³•\n",
    "\"\"\"\" \n",
    "class NeuralNetwork(nn.Module):  # å¿…é¡»ç»§æ‰¿nn.Module\n",
    "    def __init__(self):\n",
    "        super().__init__()  # å¿…é¡»è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ– super().__init__()\n",
    "        # åœ¨è¿™é‡Œå®šä¹‰ç½‘ç»œå±‚\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # åœ¨è¿™é‡Œå®šä¹‰æ•°æ®å¦‚ä½•æµåŠ¨ ï¼ˆå¿…é¡»å®ç° forward æ–¹æ³•ï¼‰\n",
    "        return x\n",
    "\n",
    "\"\"\"\" ä¾‹å­ï¼š\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\"\"\"\" \n",
    "#å®ä¾‹åŒ–æ¨¡å‹å¹¶ç§»åŠ¨åˆ°è®¾å¤‡\n",
    "# åˆ›å»ºæ¨¡å‹å®ä¾‹\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆGPU/CPUï¼‰\n",
    "model = model.to(device)\n",
    "\n",
    "# æ‰“å°æ¨¡å‹ç»“æ„\n",
    "print(model)\n",
    "\n",
    "\n",
    "#ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹\n",
    "\"\"\"\" \n",
    "Logitsï¼šåŸå§‹é¢„æµ‹åˆ†æ•°ï¼Œæœªå½’ä¸€åŒ–\n",
    "\n",
    "Softmaxï¼šå°†logitsè½¬æ¢ä¸ºæ¦‚ç‡ï¼Œæ‰€æœ‰æ¦‚ç‡å’Œä¸º1 (å„ä¸ªç±»çš„å¯èƒ½æ€§)\n",
    "\n",
    "argmaxï¼šè·å–æ¦‚ç‡æœ€å¤§çš„ç±»åˆ«ç´¢å¼• ï¼ˆæœ€å¤§å¯èƒ½æ€§çš„ç±»ï¼‰\n",
    "\"\"\"\"\n",
    "# åˆ›å»ºéšæœºè¾“å…¥æ•°æ®ï¼ˆæ¨¡æ‹Ÿä¸€å¼ 28x28çš„å›¾åƒï¼‰\n",
    "X = torch.rand(1, 28, 28, device=device)  # å½¢çŠ¶ï¼š[1, 28, 28]\n",
    "\n",
    "# ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹ï¼ˆä¸è¦ç›´æ¥è°ƒç”¨model.forward()ï¼ï¼‰\n",
    "logits = model(X)  # è‡ªåŠ¨è°ƒç”¨forwardæ–¹æ³•\n",
    "\n",
    "# å°†logitsè½¬æ¢ä¸ºæ¦‚ç‡\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "\n",
    "# è·å–é¢„æµ‹ç±»åˆ«\n",
    "y_pred = pred_probab.argmax(1)\n",
    "\n",
    "print(f\"Predicted class: {y_pred}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a4b073d-0917-4253-b081-40d48493db96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¾“å…¥å›¾åƒå¤§å°: torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Model Layers\n",
    "# åˆ›å»º3å¼ 28x28çš„éšæœºå›¾åƒï¼ˆæ¨¡æ‹Ÿä¸€ä¸ªæ‰¹æ¬¡ï¼‰\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "print(f\"è¾“å…¥å›¾åƒå¤§å°: {input_image.size()}\")  # torch.Size([3, 28, 28])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf9c086-39d4-4b42-a002-999f7f3f2485",
   "metadata": {},
   "source": [
    "æ ¸å¿ƒå±‚ç†è§£ï¼š\n",
    "\n",
    "Flattenï¼šå¤šç»´â†’ä¸€ç»´ï¼Œä¿æŒæ‰¹æ¬¡ç»´åº¦\n",
    "\n",
    "Linearï¼šå…¨è¿æ¥å±‚ï¼Œy = xW^T + b\n",
    "\n",
    "ReLUï¼šéçº¿æ€§æ¿€æ´»ï¼Œf(x) = max(0, x)\n",
    "\n",
    "Sequentialï¼šå±‚å®¹å™¨ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œ\n",
    "\n",
    "Softmaxï¼šæ¦‚ç‡å½’ä¸€åŒ–ï¼Œdimå‚æ•°å¾ˆé‡è¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d9f5a0f-452d-4b2b-b018-6e1b03fdf9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å±•å¹³åå¤§å°: torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "# nn.Flatten  Flatten layer\n",
    "# åˆ›å»ºFlattenå±‚\n",
    "flatten = nn.Flatten()\n",
    "\n",
    "# åº”ç”¨Flatten\n",
    "flat_image = flatten(input_image)\n",
    "print(f\"å±•å¹³åå¤§å°: {flat_image.size()}\")  # torch.Size([3, 784])\n",
    "\n",
    "# Flattenåšäº†ä»€ä¹ˆï¼Ÿ\n",
    "# åŸå§‹: [3, 28, 28] â†’ å±•å¹³: [3, 784]\n",
    "# ä¿æŒæ‰¹æ¬¡ç»´åº¦(3)ï¼Œå°†æ¯ä¸ª28x28å›¾åƒæ‹‰å¹³æˆ784ä¸ªåƒç´ çš„å‘é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a622c1d3-4224-4ae8-99b1-50fb0840008e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å…¨è¿æ¥å±‚è¾“å‡ºå¤§å°: torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "# nn.Linear  Linear Layer ï¼ˆæ”¹å˜ç»´åº¦ï¼Œ è°ƒæ•´å­¦ä¹ éƒ¨åˆ†ï¼‰\n",
    "# åˆ›å»ºLinear(å…¨è¿æ¥)å±‚\n",
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "\n",
    "# åº”ç”¨å…¨è¿æ¥å±‚\n",
    "hidden1 = layer1(flat_image)\n",
    "print(f\"å…¨è¿æ¥å±‚è¾“å‡ºå¤§å°: {hidden1.size()}\")  # torch.Size([3, 20])\n",
    "\n",
    "# Linearå±‚æ•°å­¦è¿ç®—ï¼š\n",
    "# output = input Ã— weight^T + bias\n",
    "# [3, 784] Ã— [784, 20]^T + [20] = [3, 20]\n",
    "\n",
    "\n",
    "# Sample\n",
    "# Linearå±‚å°†è¾“å…¥ç‰¹å¾ç©ºé—´æ˜ å°„åˆ°æ–°çš„ç‰¹å¾ç©ºé—´\n",
    "# ä¾‹å¦‚ï¼šå°†784åƒç´ å€¼ â†’ 512ä¸ªé«˜çº§ç‰¹å¾\n",
    "\n",
    "class FeatureTransformationDemo:\n",
    "    def __init__(self):\n",
    "        self.layer1 = nn.Linear(784, 256)  # 784ç»´ â†’ 256ç»´\n",
    "        self.layer2 = nn.Linear(256, 128)  # 256ç»´ â†’ 128ç»´\n",
    "        self.layer3 = nn.Linear(128, 10)   # 128ç»´ â†’ 10ç»´ï¼ˆåˆ†ç±»ï¼‰\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)  # å­¦ä¹ ä½çº§ç‰¹å¾ç»„åˆ\n",
    "        x = torch.relu(x)   # å¼•å…¥éçº¿æ€§\n",
    "        x = self.layer2(x)  # å­¦ä¹ ä¸­çº§ç‰¹å¾\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer3(x)  # å­¦ä¹ é«˜çº§ç‰¹å¾ç”¨äºåˆ†ç±»\n",
    "        return x\n",
    "\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # å°†28x28å›¾åƒå±•å¹³ä¸º784ç»´å‘é‡\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # å¤šå±‚Linearå±‚å­¦ä¹ å±‚æ¬¡ç‰¹å¾\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),  # å­¦ä¹ è¾¹ç¼˜ã€çº¹ç†ç­‰ä½çº§ç‰¹å¾\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),    # å­¦ä¹ å½¢çŠ¶ã€éƒ¨ä»¶ç­‰ä¸­çº§ç‰¹å¾  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)      # å­¦ä¹ ç±»åˆ«ç›¸å…³çš„é«˜çº§ç‰¹å¾\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202fb818-01ee-4655-a053-8f1dc93b44f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.ReLU  ReLUæ¿€æ´»å‡½æ•°\n",
    "print(\"ReLUæ¿€æ´»å‡½æ•°æ¼”ç¤º:\")\n",
    "print(f\"ReLUå‰:\\n{hidden1}\")\n",
    "\n",
    "# åº”ç”¨ReLUæ¿€æ´»å‡½æ•°\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"ReLUå:\\n{hidden1}\")\n",
    "\n",
    "# ReLUå‡½æ•°ï¼šf(x) = max(0, x)\n",
    "# ä½œç”¨ï¼šå¼•å…¥éçº¿æ€§ï¼Œè®©ç¥ç»ç½‘ç»œå¯ä»¥å­¦ä¹ å¤æ‚æ¨¡å¼\n",
    "# ç‰¹ç‚¹ï¼šå°†æ‰€æœ‰è´Ÿå€¼è®¾ä¸º0ï¼Œæ­£å€¼ä¿æŒä¸å˜\n",
    "\n",
    "# ReLUæ•ˆæœç¤ºä¾‹\n",
    "è¾“å…¥:  [0.5, -0.3, 1.2, -2.0]\n",
    "ReLUå: [0.5, 0.0, 1.2, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff21af-4b14-475e-afc6-4ea8c710692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential   ï¼ˆSequentialï¼Œ å±‚å®¹å™¨ï¼‰\n",
    "# ä½¿ç”¨Sequentialç»„åˆå¤šä¸ªå±‚\n",
    "seq_modules = nn.Sequential(\n",
    "    flatten,           # å±•å¹³å±‚\n",
    "    layer1,            # ç¬¬ä¸€ä¸ªå…¨è¿æ¥å±‚\n",
    "    nn.ReLU(),         # æ¿€æ´»å‡½æ•°\n",
    "    nn.Linear(20, 10)  # è¾“å‡ºå±‚\n",
    ")\n",
    "\n",
    "# ä½¿ç”¨Sequentialè¿›è¡Œå‰å‘ä¼ æ’­\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "logits = seq_modules(input_image)\n",
    "print(f\"Sequentialè¾“å‡ºå¤§å°: {logits.size()}\")  # torch.Size([3, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb115907-243d-4bf5-af96-b674382b19ec",
   "metadata": {},
   "source": [
    "# Softmax å‡½æ•°\n",
    "\n",
    "å¯¹äºè¾“å…¥å‘é‡ **z** = [zâ‚, zâ‚‚, ..., zâ‚–]ï¼ŒSoftmax çš„è®¡ç®—å…¬å¼ä¸ºï¼š\n",
    "\n",
    "$$\n",
    "\\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}\n",
    "$$\n",
    "\n",
    "## å…¬å¼è¯´æ˜\n",
    "\n",
    "- **záµ¢**ï¼šç¬¬ i ä¸ªç±»åˆ«çš„åŸå§‹åˆ†æ•°ï¼ˆlogitï¼‰\n",
    "- **eá¶»â±**ï¼šç¬¬ i ä¸ªç±»åˆ«çš„æŒ‡æ•°\n",
    "- **åˆ†æ¯**ï¼šæ‰€æœ‰ç±»åˆ«æŒ‡æ•°çš„æ€»å’Œ\n",
    "- **K**ï¼šç±»åˆ«æ€»æ•°\n",
    "\n",
    "## æ•°å­¦ç‰¹æ€§\n",
    "\n",
    "1. **è¾“å‡ºèŒƒå›´**ï¼šSoftmax(záµ¢) âˆˆ (0, 1)\n",
    "2. **æ¦‚ç‡åˆ†å¸ƒ**ï¼šâˆ‘ Softmax(záµ¢) = 1\n",
    "3. **å•è°ƒæ€§**ï¼šä¿æŒåŸå§‹åˆ†æ•°çš„ç›¸å¯¹é¡ºåº\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d0489-e7f8-4cbb-8e38-f881f9a0c75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Softmax  ï¼ˆSoftmaxå±‚ï¼Œæ¦‚ç‡å½’ä¸€åŒ–ï¼Œdimå‚æ•°å¾ˆé‡è¦ï¼‰\n",
    "\"\"\"\"\n",
    "Softmaxå‡½æ•°å°†ä¸€ä¸ªåŒ…å«ä»»æ„å®æ•°çš„å‘é‡ï¼ˆlogitsï¼‰è½¬æ¢ä¸ºä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒ\n",
    "æ‰€æœ‰å€¼éƒ½åœ¨(0,1)èŒƒå›´å†…\n",
    "\n",
    "æ‰€æœ‰å€¼çš„å’Œä¸º1\n",
    "\n",
    "è¾ƒå¤§çš„è¾“å…¥å€¼å¯¹åº”è¾ƒå¤§çš„è¾“å‡ºæ¦‚ç‡\n",
    "\"\"\"\"\n",
    "# åˆ›å»ºSoftmaxå±‚\n",
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "# åº”ç”¨Softmax\n",
    "pred_probab = softmax(logits)\n",
    "print(f\"Softmaxè¾“å‡º: {pred_probab}\")\n",
    "print(f\"æ¦‚ç‡æ€»å’Œ: {pred_probab.sum(dim=1)}\")  # æ¯è¡Œå’Œä¸º1.0\n",
    "\n",
    "# dim=1çš„å«ä¹‰ï¼šåœ¨å“ªä¸ªç»´åº¦ä¸Šè¿›è¡Œå½’ä¸€åŒ–\n",
    "# å¯¹äºå½¢çŠ¶ [3, 10]ï¼Œdim=1 è¡¨ç¤ºå¯¹æ¯ä¸ªæ ·æœ¬çš„10ä¸ªç±»åˆ«åˆ†æ•°è¿›è¡Œå½’ä¸€åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea6467-1286-415f-aae4-3f10da9bae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Dropout é˜²æ­¢è¿‡æ‹Ÿåˆå·¥å…·\n",
    "\"\"\"\"\n",
    "\n",
    "Dropoutæ˜¯ä¸€ç§æ­£åˆ™åŒ–æŠ€æœ¯ï¼Œ\n",
    "åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­éšæœº\"ä¸¢å¼ƒ\"ï¼ˆè®¾ç½®ä¸º0ï¼‰ä¸€éƒ¨åˆ†ç¥ç»å…ƒï¼Œ\n",
    "å¼ºåˆ¶ç½‘ç»œå­¦ä¹ æ›´é²æ£’çš„ç‰¹å¾ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ\n",
    "\n",
    "æƒ³è±¡ä½ åœ¨å‡†å¤‡è€ƒè¯•ï¼š\n",
    "\n",
    "æ²¡æœ‰Dropoutï¼šä½ åªä¾èµ–å‡ ä¸ªç‰¹å®šçš„è®°å¿†ç‚¹\n",
    "\n",
    "ä½¿ç”¨Dropoutï¼šä½ è¢«è¿«ç”¨ä¸åŒçš„æ–¹å¼å›å¿†çŸ¥è¯†ï¼Œå»ºç«‹æ›´å…¨é¢çš„ç†è§£\n",
    "\n",
    "\"\"\"\"\n",
    "    \n",
    "    # åˆ›å»ºDropoutå±‚ï¼Œp=0.5è¡¨ç¤º50%çš„ç¥ç»å…ƒä¼šè¢«éšæœºä¸¢å¼ƒ\n",
    "    dropout = nn.Dropout(p=0.5)\n",
    "    \n",
    "    # åˆ›å»ºè¾“å…¥æ•°æ®\n",
    "    input_data = torch.ones(2, 5)  # 2ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬5ä¸ªç‰¹å¾\n",
    "    print(f\"è¾“å…¥æ•°æ®:\\n{input_data}\")\n",
    "    \n",
    "    # è®­ç»ƒæ¨¡å¼ä¸‹çš„Dropout\n",
    "    dropout.train()  # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼\n",
    "    output_train = dropout(input_data)\n",
    "    print(f\"è®­ç»ƒæ¨¡å¼è¾“å‡º:\\n{output_train}\")\n",
    "    \n",
    "    # æ¨ç†æ¨¡å¼ä¸‹çš„Dropout  \n",
    "    dropout.eval()   # è®¾ç½®ä¸ºæ¨ç†æ¨¡å¼\n",
    "    output_eval = dropout(input_data)\n",
    "    print(f\"æ¨ç†æ¨¡å¼è¾“å‡º:\\n{output_eval}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dafe47a-7b1f-4f3b-a348-af9a882424d0",
   "metadata": {},
   "source": [
    "å‚æ•°ç±»å‹è¯´æ˜ï¼š\n",
    "\n",
    "weightï¼šæƒé‡çŸ©é˜µï¼Œå½¢çŠ¶ä¸º [in_features è¾“å‡ºç‰¹å¾, out_features è¾“å…¥ç‰¹å¾]\n",
    "\n",
    "biasï¼šåç½®å‘é‡ï¼Œå½¢çŠ¶ä¸º [out_features è¾“å‡ºç‰¹å¾]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b883a0-1824-4e36-aabf-8dd8b2de4d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ed8399-d478-4c75-8228-80aa32804cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e988517d-c908-486e-b519-c91e4c9709e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
