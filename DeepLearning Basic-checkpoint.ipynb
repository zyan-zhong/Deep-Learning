{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11b6d48-acd7-451e-9c60-6b68ee7cbb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------安装和初始化测试-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "066d152d-c56a-4da3-8176-55e8e324256f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp312-cp312-win_amd64.whl (2449.3 MB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp312-cp312-win_amd64.whl (6.1 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp312-cp312-win_amd64.whl (4.1 MB)\n",
      "Requirement already satisfied: filelock in d:\\jupyta\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\jupyta\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in d:\\jupyta\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in d:\\jupyta\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in d:\\jupyta\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in d:\\jupyta\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\jupyta\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\jupyta\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in d:\\jupyta\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\jupyta\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\jupyta\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121\n"
     ]
    }
   ],
   "source": [
    "# 安装支持CUDA的PyTorch版本\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e41bed99-a9e2-45ea-a0a4-ed30d4e13a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f78144b-5d2a-46bf-87fa-06a51ecfa0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 RTX 4060 GPU加速测试开始！\n",
      "==================================================\n",
      "PyTorch版本: 2.5.1+cu121\n",
      "CUDA是否可用: True\n",
      "CUDA版本: 12.1\n",
      "GPU名称: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "GPU内存: 8.0 GB\n",
      "\n",
      "使用设备: cuda\n",
      "\n",
      "🎯 开始性能对比测试...\n",
      "矩阵大小: 20000 x 20000\n",
      "⏱️  CPU计算时间: 15.4621 秒\n",
      "⚡ GPU计算时间: 2.2528 秒\n",
      "🚀 速度提升: 6.9 倍!\n",
      "✅ 结果差异: 0.006592\n",
      "\n",
      "🔧 张量操作演示...\n",
      "张量 x:\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], device='cuda:0')\n",
      "张量 y:\n",
      "tensor([[5., 6.],\n",
      "        [7., 8.]], device='cuda:0')\n",
      "\n",
      "GPU运算结果:\n",
      "x + y:\n",
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]], device='cuda:0')\n",
      "x * y:\n",
      "tensor([[ 5., 12.],\n",
      "        [21., 32.]], device='cuda:0')\n",
      "x @ y (矩阵乘法):\n",
      "tensor([[19., 22.],\n",
      "        [43., 50.]], device='cuda:0')\n",
      "\n",
      "🎓 自动求导演示...\n",
      "函数: y = x³ + 2x² + 5x + 1\n",
      "当 x = 2 时:\n",
      "y = 27.0\n",
      "dy/dx = 25.0\n",
      "\n",
      "🎉 恭喜！你的RTX 4060 GPU加速环境已完美配置！\n",
      "✨ 现在你可以享受飞快的深度学习训练速度了！\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "print(\"🚀 RTX 4060 GPU加速测试开始！\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 检查GPU状态\n",
    "print(f\"PyTorch版本: {torch.__version__}\")\n",
    "print(f\"CUDA是否可用: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA版本: {torch.version.cuda}\")\n",
    "print(f\"GPU名称: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"GPU内存: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n使用设备: {device}\")\n",
    "\n",
    "# 性能对比测试\n",
    "def performance_test():\n",
    "    print(\"\\n🎯 开始性能对比测试...\")\n",
    "    \n",
    "    # 创建大张量进行矩阵乘法\n",
    "    size = 20000\n",
    "    print(f\"矩阵大小: {size} x {size}\")\n",
    "    \n",
    "    # CPU计算\n",
    "    a_cpu = torch.randn(size, size)\n",
    "    b_cpu = torch.randn(size, size)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    result_cpu = a_cpu @ b_cpu\n",
    "    cpu_time = time.time() - start_time\n",
    "    print(f\"⏱️  CPU计算时间: {cpu_time:.4f} 秒\")\n",
    "    \n",
    "    # GPU计算\n",
    "    if torch.cuda.is_available():\n",
    "        a_gpu = a_cpu.to(device)\n",
    "        b_gpu = b_cpu.to(device)\n",
    "        \n",
    "        # 预热GPU\n",
    "        _ = a_gpu @ b_gpu\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "        start_time = time.time()\n",
    "        result_gpu = a_gpu @ b_gpu\n",
    "        torch.cuda.synchronize()\n",
    "        gpu_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"⚡ GPU计算时间: {gpu_time:.4f} 秒\")\n",
    "        print(f\"🚀 速度提升: {cpu_time/gpu_time:.1f} 倍!\")\n",
    "        \n",
    "        # 验证结果一致性\n",
    "        difference = torch.max(torch.abs(result_cpu - result_gpu.cpu()))\n",
    "        print(f\"✅ 结果差异: {difference:.6f}\")\n",
    "\n",
    "# 张量操作示例\n",
    "def tensor_operations():\n",
    "    print(\"\\n🔧 张量操作演示...\")\n",
    "    \n",
    "    # 在GPU上创建张量\n",
    "    x = torch.tensor([[1.0, 2.0], [3.0, 4.0]], device=device)\n",
    "    y = torch.tensor([[5.0, 6.0], [7.0, 8.0]], device=device)\n",
    "    \n",
    "    print(\"张量 x:\")\n",
    "    print(x)\n",
    "    print(\"张量 y:\")\n",
    "    print(y)\n",
    "    \n",
    "    # GPU上的各种运算\n",
    "    z1 = x + y  # 加法\n",
    "    z2 = x * y  # 乘法\n",
    "    z3 = x @ y  # 矩阵乘法\n",
    "    \n",
    "    print(\"\\nGPU运算结果:\")\n",
    "    print(f\"x + y:\\n{z1}\")\n",
    "    print(f\"x * y:\\n{z2}\")\n",
    "    print(f\"x @ y (矩阵乘法):\\n{z3}\")\n",
    "\n",
    "# 自动求导示例\n",
    "def autograd_demo():\n",
    "    print(\"\\n🎓 自动求导演示...\")\n",
    "    \n",
    "    # 在GPU上进行自动求导\n",
    "    x = torch.tensor(2.0, requires_grad=True, device=device)\n",
    "    y = x**3 + 2*x**2 + 5*x + 1\n",
    "    \n",
    "    y.backward()\n",
    "    print(f\"函数: y = x³ + 2x² + 5x + 1\")\n",
    "    print(f\"当 x = 2 时:\")\n",
    "    print(f\"y = {y.item()}\")\n",
    "    print(f\"dy/dx = {x.grad.item()}\")  # 导数: 3x² + 4x + 5 = 3*4 + 4*2 + 5 = 25\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    performance_test()\n",
    "    tensor_operations()\n",
    "    autograd_demo()\n",
    "    \n",
    "    print(\"\\n🎉 恭喜！你的RTX 4060 GPU加速环境已完美配置！\")\n",
    "    print(\"✨ 现在你可以享受飞快的深度学习训练速度了！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dc7422-fa81-43b3-99b4-db4e29d19ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------正文-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d610c28b-29c8-48e0-a6d2-2150bd89b518",
   "metadata": {},
   "source": [
    "Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96f714b6-63e1-46bf-b7c4-10323a55debf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.2883, 0.9344],\n",
      "        [0.2310, 0.7040]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.5848, 0.0959, 0.2012],\n",
      "        [0.0842, 0.9143, 0.4248]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n",
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "#-------tensor basic grammar-------\n",
    "\n",
    "#直接创建\n",
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "\n",
    "#从 NumPy 数组\n",
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "\n",
    "#从另一个张量 (新张量保留参数张量的属性（形状、数据类型），除非显式覆盖)\n",
    "#创建一个与 x_data 形状相同但所有元素都为1的新张量\n",
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "#创建与x_data相同形状的随机张量\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")\n",
    "\n",
    "#With random or constant values\n",
    "\n",
    "#shape is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor\n",
    "shape_1d = (5,)        # 1维，5个元素的一维数组    单元素要逗号，多元素不用管\n",
    "shape_2d = (2, 3)      # 2维，2行3列的矩阵  \n",
    "shape_3d = (2, 3, 4)   # 3维，2个3x4的矩阵\n",
    "\n",
    "shape = (2,3)\n",
    "rand_tensor = torch.rand(shape) # random variable\n",
    "ones_tensor = torch.ones(shape) # creat a tensor with all value = 1 \n",
    "zeros_tensor = torch.zeros(shape) # creat a tensor with all value = 0 \n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\") # 使用随机值或常量值\n",
    "\n",
    "# We move our tensor to the current accelerator if available\n",
    "# if torch.accelerator.is_available():\n",
    "#     tensor = tensor.to(torch.accelerator.current_accelerator())\n",
    "\n",
    "#Standard numpy-like indexing and slicing\n",
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {tensor[0]}\") # 输出第一行\n",
    "print(f\"First column: {tensor[:, 0]}\") # 输出第一列\n",
    "print(f\"Last column: {tensor[..., -1]}\") # 输出最后一列\n",
    "tensor[:,1] = 0 # 把第二列都换成0\n",
    "print(tensor)\n",
    "\n",
    "# Joinint tensors using torch.cat\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1)\n",
    "\n",
    "#Arithmetic operations\n",
    "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
    "# ``tensor.T`` returns the transpose of a tensor\n",
    "y1 = tensor @ tensor.T # 计算 tensor 与其转置的矩阵乘法\n",
    "y2 = tensor.matmul(tensor.T) # 计算 tensor 与 tensor.T 的矩阵乘法\n",
    "y3 = torch.rand_like(y1) \n",
    "torch.matmul(tensor, tensor.T, out=y3)   # 三者等效\n",
    "\n",
    "\n",
    "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
    "z1 = tensor * tensor #对 tensor 的每个元素进行平方（逐元素操作，不是矩阵乘法）\n",
    "z2 = tensor.mul(tensor) \n",
    "z3 = torch.rand_like(tensor) \n",
    "torch.mul(tensor, tensor, out=z3) # 三者等效\n",
    "\n",
    "# convert Single-element tensors to a Python numerical value using :item()\n",
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))\n",
    "\n",
    "# 原地操作 （In-place Operations）\n",
    "tensor.add_(5)  # 直接修改tensor的内容  （在原本的指令上加个下划线就是原地操作）\n",
    "\n",
    "# 非原地操作 - 创建新张量\n",
    "new_tensor = tensor.add(5)  # 不改变原tensor\n",
    "\n",
    "# PyTorch张量 → NumPy数组\n",
    "t = torch.ones(5)\n",
    "n = t.numpy()\n",
    "\n",
    "# NumPy数组 → PyTorch张量\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b93ba1-0d2c-419d-97de-0ce3ceb59edd",
   "metadata": {},
   "source": [
    "Datasets & DataLoaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa81b21-ea44-484a-ace3-20342e5f2128",
   "metadata": {},
   "source": [
    "$#-------Datasets & DataLoaders basic grammar-------$\n",
    "DataLoader的关键作用：\n",
    "\n",
    "批量处理：自动将样本组织成批次\n",
    "\n",
    "数据打乱：防止模型过拟合\n",
    "\n",
    "并行加载：使用多进程加速数据读取\n",
    "\n",
    "内存优化：支持锁页内存等优化\n",
    "\n",
    "使用模式：\n",
    "\n",
    "创建Dataset\n",
    "\n",
    "用DataLoader包装Dataset\n",
    "\n",
    "在训练循环中迭代DataLoader\n",
    "\n",
    "将批次数据传递给模型\n",
    "\n",
    "重要参数：\n",
    "\n",
    "batch_size：根据GPU内存调整\n",
    "\n",
    "shuffle：训练集为True，测试集为False\n",
    "\n",
    "num_workers：根据CPU核心数调整\n",
    "\n",
    "pin_memory：使用GPU时设为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d420b946-2709-4cd7-855b-cadbb0b3928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------创建数据集基础语法------\n",
    "#导入库\n",
    "import os # 用于处理文件路径\n",
    "import pandas as pd # 用于读取CSV标注文件\n",
    "from torchvision.io import decode_image # 从文件路径读取并解码图像为Tensor\n",
    "\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    \n",
    "    # 参数说明：\n",
    "        # annotations_file: CSV文件路径，包含图像文件名和对应标签\n",
    "        # img_dir: 图像文件存储的目录路径\n",
    "        # transform: 图像预处理变换（如调整大小、归一化等）\n",
    "        # target_transform: 标签预处理变换\n",
    "    \n",
    "    # __init__ 作用：初始化数据集对象，读取标注文件，设置图像目录和变换函数\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform  #如 transform=ToTensor(), 将图像转换为Tensor\n",
    "\n",
    "    #__len__ 作用：返回数据集中样本的数量\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels) #实现：通常返回标注文件中的行数\n",
    "\n",
    "    #__getitem__ 作用：根据索引idx获取一个样本（图像和标签）\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = decode_image(img_path) #读取图像文件并解码为PyTorch Tensor， 返回的Tensor形状为 [channels, height, width]\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:                        #应用图像变换（如归一化、数据增强等）\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:                 #应用标签变换（如one-hot编码等）\n",
    "            label = self.target_transform(label)\n",
    "        return image, label   #返回图像Tensor和对应的标签\n",
    "\n",
    "\n",
    "# 用 DataLoaders 来准备训练数据\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)  \n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_dataloader = DataLoader(\n",
    "#     dataset=training_data,      # 数据集对象\n",
    "#     batch_size=64,              # 批量大小\n",
    "#     shuffle=True,               # 是否打乱数据\n",
    "#     num_workers=4,              # 用于数据加载的子进程数\n",
    "#     pin_memory=True,            # 锁页内存，加速GPU传输\n",
    "#     drop_last=False,            # 是否丢弃最后一个不完整的批次\n",
    "#     persistent_workers=True     # 保持worker进程活跃\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "#迭代DataLoader （Iterate through the DataLoader）\n",
    "\n",
    "#基本迭代方式\n",
    "    # 方法1: 直接迭代\n",
    "    for batch_idx, (images, labels) in enumerate(train_dataloader):\n",
    "        print(f\"Batch {batch_idx}: images shape {images.shape}, labels shape {labels.shape}\")\n",
    "        \n",
    "        # 训练代码...\n",
    "        if batch_idx == 2:  # 只演示前3个批次\n",
    "            break\n",
    "\n",
    "# 使用 next(iter()) 获取单个批次\n",
    "    # 获取第一个批次进行演示\n",
    "    train_features, train_labels = next(iter(train_dataloader))\n",
    "    \n",
    "    print(f\"Feature batch shape: {train_features.size()}\")\n",
    "    print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DataLoader 高级用法\n",
    "    # 不同批量大小设置\n",
    "        # 根据任务类型设置不同的批量大小\n",
    "        small_batch_loader = DataLoader(training_data, batch_size=16, shuffle=True)   # 小批量，适合小模型\n",
    "        large_batch_loader = DataLoader(training_data, batch_size=256, shuffle=True)  # 大批量，适合大模型\n",
    "        \n",
    "        print(f\"小批量数据形状: {next(iter(small_batch_loader))[0].shape}\")  # [16, 1, 28, 28]\n",
    "        print(f\"大批量数据形状: {next(iter(large_batch_loader))[0].shape}\")  # [256, 1, 28, 28]\n",
    "\n",
    "    # 性能优化参数\n",
    "        # 优化性能的DataLoader配置\n",
    "        optimized_loader = DataLoader(\n",
    "            training_data,\n",
    "            batch_size=64,\n",
    "            shuffle=True,\n",
    "            num_workers=4,           # 并行加载进程数\n",
    "            pin_memory=True,         # 锁页内存，加速GPU数据传输\n",
    "            drop_last=True,          # 丢弃最后一个不完整批次\n",
    "            persistent_workers=True  # 保持worker进程，避免重复创建\n",
    "        )\n",
    "        \n",
    "        # 注意：在Windows上，num_workers=0可以避免一些问题\n",
    "\n",
    "# 性能优化\n",
    "    # 使用DataLoader的多进程加载\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        num_workers=4,        # 并行加载进程数\n",
    "        pin_memory=True,      # 加速GPU传输\n",
    "        persistent_workers=True  # 保持worker进程\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933577b-0de1-4a17-b15f-ddeb948e7c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----重要注意事项----\n",
    "# decode_image应该是read_image\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Transforms\n",
    "    from torchvision import transforms\n",
    "    \n",
    "    # 常用的图像变换组合\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),      # 调整大小\n",
    "        transforms.RandomHorizontalFlip(),  # 数据增强：随机水平翻转\n",
    "        transforms.ToTensor(),              # 转换为Tensor (0-1范围)\n",
    "        transforms.Normalize(               # 归一化\n",
    "            mean=[0.485, 0.456, 0.406],    # ImageNet均值\n",
    "            std=[0.229, 0.224, 0.225]      # ImageNet标准差\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    # 标签变换示例\n",
    "    def target_transform(label):\n",
    "        # 例如：将标签转换为one-hot编码\n",
    "        return torch.nn.functional.one_hot(torch.tensor(label), num_classes=10)\n",
    "\n",
    "\n",
    "# 错误处理\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "            image = read_image(img_path)\n",
    "            label = self.img_labels.iloc[idx, 1]\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            if self.target_transform:\n",
    "                label = self.target_transform(label)\n",
    "                \n",
    "            return image, label\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"加载样本 {idx} 时出错: {e}\")\n",
    "            # 返回一个默认样本或跳过\n",
    "            return torch.zeros(3, 224, 224), -1\n",
    "\n",
    "\n",
    "# 支持不同的数据格式\n",
    "class FlexibleDataset(Dataset):\n",
    "    def __init__(self, data_frame, img_dir, transform=None):\n",
    "        self.data_frame = data_frame\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data_frame.iloc[idx]\n",
    "        \n",
    "        # 支持不同的列名\n",
    "        img_path = os.path.join(self.img_dir, \n",
    "                               getattr(row, 'filename', None) or \n",
    "                               getattr(row, 'image_path', None) or \n",
    "                               row[0])\n",
    "        \n",
    "        # 支持不同的标签列名\n",
    "        label = getattr(row, 'label', None) or \\\n",
    "                getattr(row, 'class', None) or \\\n",
    "                getattr(row, 'category', None) or \\\n",
    "                row[1]\n",
    "        \n",
    "        image = read_image(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "# shuffle参数的重要性\n",
    "    # 训练集：shuffle=True（防止模型记住数据顺序）\n",
    "        train_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "    \n",
    "    # 测试集：shuffle=False（保持一致性，便于分析）\n",
    "        test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# drop_last参数\n",
    "    # 当数据集大小不能被batch_size整除时\n",
    "        dataset_size = 100\n",
    "        batch_size = 30\n",
    "            \n",
    "        loader_drop_false = DataLoader(dataset, batch_size=30, drop_last=False)\n",
    "        loader_drop_true = DataLoader(dataset, batch_size=30, drop_last=True)\n",
    "        \n",
    "        print(f\"drop_last=False 的批次数: {len(loader_drop_false)}\")  # 4个批次 (30,30,30,10)\n",
    "        print(f\"drop_last=True 的批次数: {len(loader_drop_true)}\")   # 3个批次 (30,30,30)\n",
    "\n",
    "# 内存管理\n",
    "    # 监控数据加载的内存使用\n",
    "        for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "            print(f\"批次 {batch_idx} 内存使用: {data.element_size() * data.nelement() / 1024 / 1024:.2f} MB\")\n",
    "            \n",
    "            if batch_idx == 0:\n",
    "                # 检查设备\n",
    "                print(f\"数据设备: {data.device}\")\n",
    "                print(f\"标签设备: {target.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2547cb-42a1-48a7-8c74-d9a6b1ed502c",
   "metadata": {},
   "source": [
    "$DataLoader 完整公式化例程$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad51c6f5-2aca-4066-9be9-03455cf58d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 设置随机种子保证可重复性\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class CompleteDataLoaderExample:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"使用设备: {self.device}\")\n",
    "        \n",
    "        # 数据变换\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "        \n",
    "        # 加载数据\n",
    "        self.train_dataset, self.test_dataset = self.load_data()\n",
    "        \n",
    "        # 创建DataLoader\n",
    "        self.train_loader, self.test_loader = self.create_dataloaders()\n",
    "        \n",
    "        # 创建模型\n",
    "        self.model = self.create_model().to(self.device)\n",
    "        \n",
    "        # 定义损失函数和优化器\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        \n",
    "        # 训练记录\n",
    "        self.train_losses = []\n",
    "        self.test_accuracies = []\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"加载训练和测试数据集\"\"\"\n",
    "        print(\"正在下载和加载数据...\")\n",
    "        \n",
    "        train_dataset = datasets.FashionMNIST(\n",
    "            root='./data',\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=self.transform\n",
    "        )\n",
    "        \n",
    "        test_dataset = datasets.FashionMNIST(\n",
    "            root='./data',\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=self.transform\n",
    "        )\n",
    "        \n",
    "        print(f\"训练集大小: {len(train_dataset)}\")\n",
    "        print(f\"测试集大小: {len(test_dataset)}\")\n",
    "        \n",
    "        return train_dataset, test_dataset\n",
    "\n",
    "    def create_dataloaders(self):\n",
    "        \"\"\"创建训练和测试DataLoader\"\"\"\n",
    "        train_loader = DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=64,\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        test_loader = DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=1000,\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        print(f\"训练批次数: {len(train_loader)}\")\n",
    "        print(f\"测试批次数: {len(test_loader)}\")\n",
    "        \n",
    "        return train_loader, test_loader\n",
    "\n",
    "    def create_model(self):\n",
    "        \"\"\"创建简单的神经网络模型\"\"\"\n",
    "        class SimpleNN(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(SimpleNN, self).__init__()\n",
    "                self.flatten = nn.Flatten()\n",
    "                self.linear_relu_stack = nn.Sequential(\n",
    "                    nn.Linear(28*28, 512),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(512, 512),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(512, 10)\n",
    "                )\n",
    "            \n",
    "            def forward(self, x):\n",
    "                x = self.flatten(x)\n",
    "                logits = self.linear_relu_stack(x)\n",
    "                return logits\n",
    "        \n",
    "        return SimpleNN()\n",
    "\n",
    "    def train_epoch(self, epoch):\n",
    "        \"\"\"训练一个epoch\"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "            # 将数据移动到设备\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            \n",
    "            # 前向传播\n",
    "            self.optimizer.zero_grad()\n",
    "            output = self.model(data)\n",
    "            loss = self.criterion(output, target)\n",
    "            \n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            # 每100个批次打印一次进度\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(self.train_loader.dataset)} '\n",
    "                      f'({100. * batch_idx / len(self.train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "        \n",
    "        avg_loss = running_loss / len(self.train_loader)\n",
    "        self.train_losses.append(avg_loss)\n",
    "        return avg_loss\n",
    "\n",
    "    def test(self):\n",
    "        \"\"\"测试模型性能\"\"\"\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data, target in self.test_loader:\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                output = self.model(data)\n",
    "                test_loss += self.criterion(output, target).item()\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        test_loss /= len(self.test_loader)\n",
    "        accuracy = 100. * correct / len(self.test_loader.dataset)\n",
    "        self.test_accuracies.append(accuracy)\n",
    "        \n",
    "        print(f'\\n测试集: 平均损失: {test_loss:.4f}, 准确率: {correct}/{len(self.test_loader.dataset)} '\n",
    "              f'({accuracy:.2f}%)\\n')\n",
    "        \n",
    "        return accuracy\n",
    "\n",
    "    def visualize_batch(self, num_images=12):\n",
    "        \"\"\"可视化一个批次的样本\"\"\"\n",
    "        # 获取一个批次\n",
    "        data_iter = iter(self.train_loader)\n",
    "        images, labels = next(data_iter)\n",
    "        \n",
    "        # 标签映射\n",
    "        class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                      'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "        \n",
    "        # 创建图像网格\n",
    "        fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "        for i in range(num_images):\n",
    "            ax = axes[i // 4, i % 4]\n",
    "            image = images[i].squeeze()\n",
    "            label = labels[i].item()\n",
    "            \n",
    "            ax.imshow(image, cmap='gray')\n",
    "            ax.set_title(f'{class_names[label]} ({label})')\n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def visualize_training(self):\n",
    "        \"\"\"可视化训练过程\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        # 训练损失\n",
    "        ax1.plot(self.train_losses)\n",
    "        ax1.set_title('训练损失')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # 测试准确率\n",
    "        ax2.plot(self.test_accuracies)\n",
    "        ax2.set_title('测试准确率')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Accuracy (%)')\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def run_training(self, epochs=5):\n",
    "        \"\"\"运行完整训练过程\"\"\"\n",
    "        print(\"开始训练...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(1, epochs + 1):\n",
    "            epoch_start = time.time()\n",
    "            \n",
    "            # 训练一个epoch\n",
    "            train_loss = self.train_epoch(epoch)\n",
    "            \n",
    "            # 测试\n",
    "            test_accuracy = self.test()\n",
    "            \n",
    "            epoch_time = time.time() - epoch_start\n",
    "            print(f'Epoch {epoch} 完成, 耗时: {epoch_time:.2f}秒')\n",
    "            print('-' * 50)\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f'训练完成! 总耗时: {total_time:.2f}秒')\n",
    "        \n",
    "        # 可视化训练过程\n",
    "        self.visualize_training()\n",
    "\n",
    "    def demonstrate_dataloader_features(self):\n",
    "        \"\"\"演示DataLoader的各种特性\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"DataLoader 特性演示\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # 1. 显示批次信息\n",
    "        print(\"1. 批次信息:\")\n",
    "        for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "            if batch_idx == 0:\n",
    "                print(f\"  数据形状: {data.shape}\")  # [batch_size, channels, height, width]\n",
    "                print(f\"  标签形状: {target.shape}\")  # [batch_size]\n",
    "                print(f\"  数据类型: {data.dtype}\")\n",
    "                print(f\"  数据范围: [{data.min():.3f}, {data.max():.3f}]\")\n",
    "            break\n",
    "        \n",
    "        # 2. 显示shuffle效果\n",
    "        print(\"\\n2. Shuffle效果演示:\")\n",
    "        first_batch_labels = []\n",
    "        for i in range(3):\n",
    "            data_iter = iter(self.train_loader)\n",
    "            _, labels = next(data_iter)\n",
    "            first_batch_labels.append(labels[:5].tolist())  # 前5个标签\n",
    "        \n",
    "        print(\"   前3次迭代的第一个批次的前5个标签:\")\n",
    "        for i, labels in enumerate(first_batch_labels):\n",
    "            print(f\"   迭代 {i+1}: {labels}\")\n",
    "        \n",
    "        # 3. 显示数据集信息\n",
    "        print(\"\\n3. 数据集统计:\")\n",
    "        print(f\"   训练集总样本数: {len(self.train_loader.dataset)}\")\n",
    "        print(f\"   测试集总样本数: {len(self.test_loader.dataset)}\")\n",
    "        print(f\"   训练批次数: {len(self.train_loader)}\")\n",
    "        print(f\"   测试批次数: {len(self.test_loader)}\")\n",
    "        print(f\"   批次大小: {self.train_loader.batch_size}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    # 创建示例\n",
    "    example = CompleteDataLoaderExample()\n",
    "    \n",
    "    # 可视化一些样本\n",
    "    print(\"正在可视化训练样本...\")\n",
    "    example.visualize_batch()\n",
    "    \n",
    "    # 演示DataLoader特性\n",
    "    example.demonstrate_dataloader_features()\n",
    "    \n",
    "    # 运行训练\n",
    "    example.run_training(epochs=5)\n",
    "    \n",
    "    # 保存模型\n",
    "    torch.save(example.model.state_dict(), 'fashion_mnist_model.pth')\n",
    "    print(\"模型已保存为 'fashion_mnist_model.pth'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b005b955-96ad-4349-9d7d-2b129bb3a46a",
   "metadata": {},
   "source": [
    "$关键组件说明 数据加载 → 模型定义 → 训练 → 测试 → 可视化$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631e3786-1013-4682-b7c4-1e85972a019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 数据加载和预处理\n",
    "# 标准数据变换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),           # 转换为Tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # 归一化到[-1,1]\n",
    "])\n",
    "\n",
    "# 数据集加载\n",
    "train_dataset = datasets.FashionMNIST(...)\n",
    "test_dataset = datasets.FashionMNIST(...)\n",
    "\n",
    "#2 DataLoader配置\n",
    "# 训练DataLoader - 打乱数据，适合训练\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True,        # 重要：训练时需要打乱\n",
    "    num_workers=2,       # 并行加载进程\n",
    "    pin_memory=True      # 加速GPU传输\n",
    ")\n",
    "\n",
    "# 测试DataLoader - 不打乱数据，适合评估\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1000,     # 测试时可以用更大的批次\n",
    "    shuffle=False,       # 重要：测试时不需要打乱\n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "#3 标准训练循环模板\n",
    "def train_epoch(self, epoch):\n",
    "    self.model.train()  # 设置为训练模式\n",
    "    for batch_idx, (data, target) in enumerate(self.train_loader):\n",
    "        # 1. 数据移动到设备\n",
    "        data, target = data.to(self.device), target.to(self.device)\n",
    "        \n",
    "        # 2. 梯度清零\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # 3. 前向传播\n",
    "        output = self.model(data)\n",
    "        loss = self.criterion(output, target)\n",
    "        \n",
    "        # 4. 反向传播\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. 参数更新\n",
    "        self.optimizer.step()\n",
    "\n",
    "#4 标准测试循环模板\n",
    "def test(self):\n",
    "    self.model.eval()  # 设置为评估模式\n",
    "    with torch.no_grad():  # 禁用梯度计算\n",
    "        for data, target in self.test_loader:\n",
    "            data, target = data.to(self.device), target.to(self.device)\n",
    "            output = self.model(data)\n",
    "            # 计算准确率等指标..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36374860-02a2-4077-8cce-f88024085546",
   "metadata": {},
   "source": [
    "$Transforms$\n",
    "\n",
    "$Transforms是数据预处理的工具，用于将原始数据转换为适合模型训练的格式$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56244a7-47db-4eb1-a0f2-aebcde9efea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "# 应用ToTensor转换\n",
    "to_tensor = ToTensor()\n",
    "tensor_image = to_tensor(pil_image)\n",
    "\n",
    "# Lambda Transforms\n",
    "target_transform = Lambda(lambda y: torch.zeros(\n",
    "    10, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))\n",
    "\n",
    "    # Within Lambda Transforms\n",
    "        # 步骤1: 创建全零张量\n",
    "            zero_tensor = torch.zeros(10, dtype=torch.float)\n",
    "            # tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "        \n",
    "        # 步骤2: 使用scatter_在指定位置设置值\n",
    "            result = zero_tensor.scatter_(dim=0, index=torch.tensor(3), value=1)\n",
    "            # tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])\n",
    "\n",
    "# 常用Transforms\n",
    "from torchvision import transforms\n",
    "\n",
    "# 常用的图像变换组合\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),                    # 调整大小\n",
    "    transforms.CenterCrop(224),                # 中心裁剪\n",
    "    transforms.RandomHorizontalFlip(0.5),     # 随机水平翻转\n",
    "    transforms.RandomRotation(10),             # 随机旋转\n",
    "    transforms.ColorJitter(0.2, 0.2, 0.2),    # 颜色抖动\n",
    "    transforms.ToTensor(),                     # 转换为Tensor\n",
    "    transforms.Normalize(                      # 归一化\n",
    "        mean=[0.485, 0.456, 0.406],           # ImageNet均值\n",
    "        std=[0.229, 0.224, 0.225]             # ImageNet标准差\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b843f9c5-7e65-4097-90d2-46e4db4afc84",
   "metadata": {},
   "source": [
    "$ToTensor()$完成两个主要转换：\n",
    "\n",
    "转换前：PIL Image 或 numpy.ndarray\n",
    "\n",
    "转换后：torch.FloatTensor\n",
    "\n",
    "具体变化：\n",
    "1. 数据类型：PIL/NumPy → torch.Tensor\n",
    "2. 数值范围：[0, 255] → [0.0, 1.0]\n",
    "3. 维度顺序：(H, W, C) → (C, H, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a041db77-28a9-4efc-bced-2da9511ea30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实际应用（训练和测试的不同变换）\n",
    "    # 训练变换：包含数据增强\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # 测试变换：只有基础变换\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # 分别应用于训练集和测试集\n",
    "    train_dataset = datasets.FashionMNIST(\n",
    "        root=\"data\", train=True, download=True, transform=train_transform\n",
    "    )\n",
    "    \n",
    "    test_dataset = datasets.FashionMNIST(\n",
    "        root=\"data\", train=False, download=True, transform=test_transform\n",
    "    )\n",
    "\n",
    "#----注意事项----\n",
    "    # 变换的顺序很重要\n",
    "        # 错误顺序\n",
    "        wrong_order = transforms.Compose([\n",
    "            transforms.Normalize((0.5,), (0.5,)),  # 错误：在ToTensor之前\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        \n",
    "        # 正确顺序\n",
    "        correct_order = transforms.Compose([\n",
    "            transforms.ToTensor(),                  # 先转换为Tensor\n",
    "            transforms.Normalize((0.5,), (0.5,))   # 然后归一化\n",
    "        ])\n",
    "    \n",
    "    # 内存和性能考虑\n",
    "        # 避免在变换中进行昂贵的操作\n",
    "        # 不好：在每次获取样本时都进行复杂计算\n",
    "        expensive_transform = Lambda(lambda x: complicated_processing(x))\n",
    "        \n",
    "        # 好：预处理或使用缓存的变换\n",
    "        efficient_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "    \n",
    "    # 数据类型一致性\n",
    "        # 确保变换后的数据类型与模型期望一致\n",
    "        def check_data_types(dataset):\n",
    "            image, label = dataset[0]\n",
    "            \n",
    "            print(f\"图像类型: {image.dtype}\")    # 应该是torch.float32\n",
    "            print(f\"标签类型: {label.dtype}\")    # 应该是torch.float32（对于one-hot）\n",
    "            \n",
    "            # 模型通常期望float32输入\n",
    "            assert image.dtype == torch.float32, f\"图像数据类型错误: {image.dtype}\"\n",
    "            assert label.dtype == torch.float32, f\"标签数据类型错误: {label.dtype}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693095d1-2f8d-4701-8fd2-c8c4c54f5969",
   "metadata": {},
   "source": [
    "$Build-the-Neural-Network$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c6246a-d81f-4fce-9828-43a2ecdb8b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary library\n",
    "import os\n",
    "import torch\n",
    "from torch import nn  # 神经网络核心模块 torch.nn：包含所有神经网络层和损失函数\n",
    "from torch.utils.data import DataLoader  # 数据加载 DataLoader：用于批量加载数据\n",
    "from torchvision import datasets, transforms  # 计算机视觉相关 torchvision：提供预训练模型和数据集\n",
    "\n",
    "\n",
    "# Get Device for Training\n",
    "# 方法1：使用最新的加速器API（推荐）\n",
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "    # 方法2：传统方法（兼容性更好）\n",
    "        # if torch.cuda.is_available():\n",
    "        #     device = \"cuda\"\n",
    "        # elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        #     device = \"mps\"  # Apple Silicon\n",
    "        # else:\n",
    "        #     device = \"cpu\"\n",
    "\n",
    "\n",
    "# Define the Class 神经网络类的骨架\n",
    "\"\"\"\" \n",
    "关键规则：\n",
    "\n",
    "必须继承 nn.Module\n",
    "\n",
    "必须调用 super().__init__()\n",
    "\n",
    "必须实现 forward 方法\n",
    "\"\"\"\" \n",
    "class NeuralNetwork(nn.Module):  # 必须继承nn.Module\n",
    "    def __init__(self):\n",
    "        super().__init__()  # 必须调用父类初始化 super().__init__()\n",
    "        # 在这里定义网络层\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 在这里定义数据如何流动 （必须实现 forward 方法）\n",
    "        return x\n",
    "\n",
    "\"\"\"\" 例子：\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\"\"\"\" \n",
    "#实例化模型并移动到设备\n",
    "# 创建模型实例\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# 将模型移动到指定设备（GPU/CPU）\n",
    "model = model.to(device)\n",
    "\n",
    "# 打印模型结构\n",
    "print(model)\n",
    "\n",
    "\n",
    "#使用模型进行预测\n",
    "\"\"\"\" \n",
    "Logits：原始预测分数，未归一化\n",
    "\n",
    "Softmax：将logits转换为概率，所有概率和为1 (各个类的可能性)\n",
    "\n",
    "argmax：获取概率最大的类别索引 （最大可能性的类）\n",
    "\"\"\"\"\n",
    "# 创建随机输入数据（模拟一张28x28的图像）\n",
    "X = torch.rand(1, 28, 28, device=device)  # 形状：[1, 28, 28]\n",
    "\n",
    "# 使用模型进行预测（不要直接调用model.forward()！）\n",
    "logits = model(X)  # 自动调用forward方法\n",
    "\n",
    "# 将logits转换为概率\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "\n",
    "# 获取预测类别\n",
    "y_pred = pred_probab.argmax(1)\n",
    "\n",
    "print(f\"Predicted class: {y_pred}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a4b073d-0917-4253-b081-40d48493db96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入图像大小: torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Model Layers\n",
    "# 创建3张28x28的随机图像（模拟一个批次）\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "print(f\"输入图像大小: {input_image.size()}\")  # torch.Size([3, 28, 28])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf9c086-39d4-4b42-a002-999f7f3f2485",
   "metadata": {},
   "source": [
    "核心层理解：\n",
    "\n",
    "Flatten：多维→一维，保持批次维度\n",
    "\n",
    "Linear：全连接层，y = xW^T + b\n",
    "\n",
    "ReLU：非线性激活，f(x) = max(0, x)\n",
    "\n",
    "Sequential：层容器，按顺序执行\n",
    "\n",
    "Softmax：概率归一化，dim参数很重要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d9f5a0f-452d-4b2b-b018-6e1b03fdf9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "展平后大小: torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "# nn.Flatten  Flatten layer\n",
    "# 创建Flatten层\n",
    "flatten = nn.Flatten()\n",
    "\n",
    "# 应用Flatten\n",
    "flat_image = flatten(input_image)\n",
    "print(f\"展平后大小: {flat_image.size()}\")  # torch.Size([3, 784])\n",
    "\n",
    "# Flatten做了什么？\n",
    "# 原始: [3, 28, 28] → 展平: [3, 784]\n",
    "# 保持批次维度(3)，将每个28x28图像拉平成784个像素的向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a622c1d3-4224-4ae8-99b1-50fb0840008e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "全连接层输出大小: torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "# nn.Linear  Linear Layer （改变维度， 调整学习部分）\n",
    "# 创建Linear(全连接)层\n",
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "\n",
    "# 应用全连接层\n",
    "hidden1 = layer1(flat_image)\n",
    "print(f\"全连接层输出大小: {hidden1.size()}\")  # torch.Size([3, 20])\n",
    "\n",
    "# Linear层数学运算：\n",
    "# output = input × weight^T + bias\n",
    "# [3, 784] × [784, 20]^T + [20] = [3, 20]\n",
    "\n",
    "\n",
    "# Sample\n",
    "# Linear层将输入特征空间映射到新的特征空间\n",
    "# 例如：将784像素值 → 512个高级特征\n",
    "\n",
    "class FeatureTransformationDemo:\n",
    "    def __init__(self):\n",
    "        self.layer1 = nn.Linear(784, 256)  # 784维 → 256维\n",
    "        self.layer2 = nn.Linear(256, 128)  # 256维 → 128维\n",
    "        self.layer3 = nn.Linear(128, 10)   # 128维 → 10维（分类）\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)  # 学习低级特征组合\n",
    "        x = torch.relu(x)   # 引入非线性\n",
    "        x = self.layer2(x)  # 学习中级特征\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer3(x)  # 学习高级特征用于分类\n",
    "        return x\n",
    "\n",
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 将28x28图像展平为784维向量\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # 多层Linear层学习层次特征\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),  # 学习边缘、纹理等低级特征\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),    # 学习形状、部件等中级特征  \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)      # 学习类别相关的高级特征\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202fb818-01ee-4655-a053-8f1dc93b44f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.ReLU  ReLU激活函数\n",
    "print(\"ReLU激活函数演示:\")\n",
    "print(f\"ReLU前:\\n{hidden1}\")\n",
    "\n",
    "# 应用ReLU激活函数\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"ReLU后:\\n{hidden1}\")\n",
    "\n",
    "# ReLU函数：f(x) = max(0, x)\n",
    "# 作用：引入非线性，让神经网络可以学习复杂模式\n",
    "# 特点：将所有负值设为0，正值保持不变\n",
    "\n",
    "# ReLU效果示例\n",
    "输入:  [0.5, -0.3, 1.2, -2.0]\n",
    "ReLU后: [0.5, 0.0, 1.2, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff21af-4b14-475e-afc6-4ea8c710692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential   （Sequential， 层容器）\n",
    "# 使用Sequential组合多个层\n",
    "seq_modules = nn.Sequential(\n",
    "    flatten,           # 展平层\n",
    "    layer1,            # 第一个全连接层\n",
    "    nn.ReLU(),         # 激活函数\n",
    "    nn.Linear(20, 10)  # 输出层\n",
    ")\n",
    "\n",
    "# 使用Sequential进行前向传播\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "logits = seq_modules(input_image)\n",
    "print(f\"Sequential输出大小: {logits.size()}\")  # torch.Size([3, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb115907-243d-4bf5-af96-b674382b19ec",
   "metadata": {},
   "source": [
    "# Softmax 函数\n",
    "\n",
    "对于输入向量 **z** = [z₁, z₂, ..., zₖ]，Softmax 的计算公式为：\n",
    "\n",
    "$$\n",
    "\\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j=1}^{K} e^{z_j}}\n",
    "$$\n",
    "\n",
    "## 公式说明\n",
    "\n",
    "- **zᵢ**：第 i 个类别的原始分数（logit）\n",
    "- **eᶻⁱ**：第 i 个类别的指数\n",
    "- **分母**：所有类别指数的总和\n",
    "- **K**：类别总数\n",
    "\n",
    "## 数学特性\n",
    "\n",
    "1. **输出范围**：Softmax(zᵢ) ∈ (0, 1)\n",
    "2. **概率分布**：∑ Softmax(zᵢ) = 1\n",
    "3. **单调性**：保持原始分数的相对顺序\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d0489-e7f8-4cbb-8e38-f881f9a0c75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Softmax  （Softmax层，概率归一化，dim参数很重要）\n",
    "\"\"\"\"\n",
    "Softmax函数将一个包含任意实数的向量（logits）转换为一个概率分布\n",
    "所有值都在(0,1)范围内\n",
    "\n",
    "所有值的和为1\n",
    "\n",
    "较大的输入值对应较大的输出概率\n",
    "\"\"\"\"\n",
    "# 创建Softmax层\n",
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "# 应用Softmax\n",
    "pred_probab = softmax(logits)\n",
    "print(f\"Softmax输出: {pred_probab}\")\n",
    "print(f\"概率总和: {pred_probab.sum(dim=1)}\")  # 每行和为1.0\n",
    "\n",
    "# dim=1的含义：在哪个维度上进行归一化\n",
    "# 对于形状 [3, 10]，dim=1 表示对每个样本的10个类别分数进行归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ea6467-1286-415f-aae4-3f10da9bae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Dropout 防止过拟合工具\n",
    "\"\"\"\"\n",
    "\n",
    "Dropout是一种正则化技术，\n",
    "在训练过程中随机\"丢弃\"（设置为0）一部分神经元，\n",
    "强制网络学习更鲁棒的特征，防止过拟合\n",
    "\n",
    "想象你在准备考试：\n",
    "\n",
    "没有Dropout：你只依赖几个特定的记忆点\n",
    "\n",
    "使用Dropout：你被迫用不同的方式回忆知识，建立更全面的理解\n",
    "\n",
    "\"\"\"\"\n",
    "    \n",
    "    # 创建Dropout层，p=0.5表示50%的神经元会被随机丢弃\n",
    "    dropout = nn.Dropout(p=0.5)\n",
    "    \n",
    "    # 创建输入数据\n",
    "    input_data = torch.ones(2, 5)  # 2个样本，每个样本5个特征\n",
    "    print(f\"输入数据:\\n{input_data}\")\n",
    "    \n",
    "    # 训练模式下的Dropout\n",
    "    dropout.train()  # 设置为训练模式\n",
    "    output_train = dropout(input_data)\n",
    "    print(f\"训练模式输出:\\n{output_train}\")\n",
    "    \n",
    "    # 推理模式下的Dropout  \n",
    "    dropout.eval()   # 设置为推理模式\n",
    "    output_eval = dropout(input_data)\n",
    "    print(f\"推理模式输出:\\n{output_eval}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dafe47a-7b1f-4f3b-a348-af9a882424d0",
   "metadata": {},
   "source": [
    "参数类型说明：\n",
    "\n",
    "weight：权重矩阵，形状为 [in_features 输出特征, out_features 输入特征]\n",
    "\n",
    "bias：偏置向量，形状为 [out_features 输出特征]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b883a0-1824-4e36-aabf-8dd8b2de4d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Parameters\n",
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ed8399-d478-4c75-8228-80aa32804cad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e988517d-c908-486e-b519-c91e4c9709e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
